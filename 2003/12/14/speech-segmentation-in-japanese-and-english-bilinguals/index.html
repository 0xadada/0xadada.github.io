<!DOCTYPE html><html lang="en-US"><head><meta charSet="utf-8"/><meta name="viewport" content="width=device-width, initial-scale=1"/><link rel="preload" as="image" href="/static/images/meta/avatar.svg"/><link rel="stylesheet" href="/_next/static/css/32a94118522b884a.css" crossorigin="" data-precedence="next"/><link rel="stylesheet" href="/_next/static/css/ec967fd209f0dd40.css" crossorigin="" data-precedence="next"/><link rel="preload" as="script" fetchPriority="low" href="/_next/static/chunks/webpack-bb5b7c6ade2286d3.js" crossorigin=""/><script src="/_next/static/chunks/fd9d1056-cc48c28d170fddc2.js" async="" crossorigin=""></script><script src="/_next/static/chunks/69-0a6331c18b0d37aa.js" async="" crossorigin=""></script><script src="/_next/static/chunks/main-app-715e3a652bc6b546.js" async="" crossorigin=""></script><script src="/_next/static/chunks/250-d7e0a94ebe194dac.js" async=""></script><script src="/_next/static/chunks/app/page-f7ba098afe402509.js" async=""></script><title>Speech Segmentation in Japanese and English Bilinguals</title><meta name="description" content="The purpose of this paper is to provide an overview of the existing literature concerning speech segmentation, categorical perception, and some other issues concerning bilinguals of English and Japanese"/><link rel="author" href="https://0xadada.pub"/><meta name="author" content="0xADADA"/><meta name="keywords" content="essays,Japanese"/><link rel="alternate" type="application/rss+xml" href="https://0xadada.pub/rss.xml"/><meta property="og:title" content="Speech Segmentation in Japanese and English Bilinguals"/><meta property="og:description" content="The purpose of this paper is to provide an overview of the existing literature concerning speech segmentation, categorical perception, and some other issues concerning bilinguals of English and Japanese"/><meta property="og:url" content="https://0xadada.pub/2003/12/14/speech-segmentation-in-japanese-and-english-bilinguals/"/><meta property="og:site_name" content="0xADADA"/><meta property="og:locale" content="en_US"/><meta property="og:image" content="https://0xadada.pub/static/images/meta/avatar.svg"/><meta property="og:image:width" content="660"/><meta property="og:image:height" content="660"/><meta property="og:type" content="article"/><meta name="twitter:card" content="summary_large_image"/><meta name="twitter:title" content="Speech Segmentation in Japanese and English Bilinguals"/><meta name="twitter:description" content="The purpose of this paper is to provide an overview of the existing literature concerning speech segmentation, categorical perception, and some other issues concerning bilinguals of English and Japanese"/><meta name="twitter:image" content="https://0xadada.pub/static/images/meta/avatar.svg"/><meta name="twitter:image:width" content="660"/><meta name="twitter:image:height" content="660"/><link rel="icon" href="/favicon.ico" type="image/x-icon" sizes="48x48"/><link rel="apple-touch-icon" href="/apple-icon.png?b764b3a1dbf00a82" type="image/png" sizes="180x180"/><script src="/_next/static/chunks/polyfills-c67a75d1b6f99dc8.js" crossorigin="" noModule=""></script></head><body><main class="layout_layout__dCqca"><article class="hentry h-entry"><header><h1 class="entry-title p-name">Speech Segmentation in Japanese and English Bilinguals</h1><time class="display-date_published__A_L_d dt-published" dateTime="2003-12-14T00:00:00.000Z">Sunday December 14, 2003</time><br/><span class="h-card page_byline___vuXv">by:<!-- --> <span class="page_author__cAd1d fn p-author p-name">0xADADA</span></span></header><div class="entry-content e-content"><p>Colleges of Computer Sciences and Science (Psychology)</p>
<br/>
<p>Northeastern University Boston, MA</p>
<br/>
<p>Topics Concerning Japanese and English Bilinguals</p>
<h3>A Literature Review</h3>
<hr/>
<p>The purpose of this paper is to provide an overview of the existing literature concerning speech segmentation, categorical perception, and some other issues concerning bilinguals of English and Japanese. It will touch on some of the differences in the two languages and how they affect learning the L2. The paper will start by providing background information about some of the two languages and some of the current issues involved in speech processing. The paper will then delve into the most current research, what the issues are, how it was done, and the results they have found. It will then go on to discuss the possible future directions of this research and end with references.</p>
<hr/>
<h2>I. Introduction</h2>
<p>People trying to learn a second language always have a difficult task ahead of
them. Learning a new grammar and lexicon takes both time and practice. Some
languages are diverse enough that on top of a new lexicon and grammar, there is
also an entirely new segmentation system to be learned. Japanese and English are
diverse in the way the speech streams are segmented into parts, with Japanese
using the mora as the basic unit of perception (McQueen, Otake &amp; Cutler, 2001)
and English using stress (Cutler &amp; Butterfield, 1992). Along with learning a new
lexicon, grammar, and segmentation system is the problems with categorical
perception. How can bilinguals learn new sounds that aren’t in their native
language? Another important issue is if there are multiple segmentation cues,
can there be universal segmentation cues besides the rhythm-based mora, syllable
and stress-based processes? This paper will try to uncover these questions.</p>
<h3>Background</h3>
<p>When participating in conversation the listener must do a myriad of tasks to
comprehend what the other speaker is saying. On the physical side of things, the
comprehended must process the sound waves from the air into electrical signals
into the brain. From there he/she must then begin the process of turning sound
signals into words, phrases, sentences, and finally into a complete dialog. The
aspect of changing the raw speech stream into words is called speech
segmentation (Cutler, Hehler, Norris &amp; Segui, 1986). Speech segmentation is
usually accomplished in different ways according to the language, the major
rhythm-based segmentation types are mora in Japanese, syllable in French
(Cutler, Hehler, Norris &amp; Segui, 1986), and stress in English. The mora is the
smallest Japanese unit of perception, it is subsyllabic. <em>“It can be a vocalic
nucleus, a nucleus plus syllable onset, or, as in the second and fourth morae of
shinshinto, it can be the postvocalic portion of a syllable, i.e., the coda.”</em>
(Otake, Hatano, Cutler &amp; Mehler, 1993). Japanese is a “mora-timed” language,
where each mora represents a rhythmic unit; in comparison to English which is
“stress-timed” (Beckman, 1982). There has been much research into the field of
speech segmentation, specifically into the types listed above including
stressed-base and syllable-based (Cutler, Mehler, Norris &amp; Segui, 1986), as well
as mora-based (Cutler &amp; Otake, 1994). There has also been a fair amount of study
on phoneme discrimination of /r/ and /l/ in native speakers of Japanese and
English. One particular study (Miyawaki, Strange &amp; Verbrugge, Liberman, Jenkins
&amp; Fujimura, 1975) used synthesized speech to compare Americans and Japanese at
discriminating /ra/ and /la/. A follow-up study a few years later reinforced
previous findings that Americans can categorically discriminate the phonemes,
and that Japanese are at a near-chance level of perception (Strange &amp; Dittmann,
1984). This study also showed that after training, the native Japanese
performance on those phones increased, and therefore categorical perception is
indeed possible for non-native speakers.</p>
<h2>II. Review of the existing literature</h2>
<h3>1. Discrimination of /r/ and /l/ by native speakers of Japanese and English</h3>
<p>Categorical perception of speech sounds is an important aspect of speech
segmentation. Without the ability to properly hear differences in non-native
speech sounds, then segmentation and comprehension will be negatively impaired.
One of the seminal research papers written comparing the abilities of English
and Japanese natives to discriminate the /r/ and /l/ sound was by Miyawaki,
Strange, Verbrugge, Liberman, Jenkins and Fujimura in 1975. The research here
confirms earlier findings that Japanese subjects cannot distinguish between /r/
and /l/ (Goto, 1971). This paper investigated the effects of linguistic use on
the ability to discriminate the class of liquid phones in English and Japanese
natives. They focused on the phonemes /l/ and /r/ in syllable-initial position.
The choice for the liquid /l/ and /r/ phones were made due to the fact that
<em>“the distinction between these phones is phonemic in English but not in
Japnanese.”</em> (Miyawaki et al., 1975). The /r/ and /l/ phones don’t constitute a
phonemic contrast in Japanese, and therefore would provide a good base to
conduct tests on the differences in native and non-native discrimination tasks.
This research paper used a speech sound generator to create a series of sounds
between two phones in order to see where and how categorical perception would
occur. The parallel-resonance synthesizer generated 15 3-formant sounds that
would be used in the tests. The third formant (F3) was varied in frequency in
steps between the /ra/ and /la/ sounds. From this set of 15 sounds, there would
be two types of tests conducted on each subject group, an identification test
and an oddity discrimination test. The subjects of this research consisted of 39
native American speakers and 21 native Japanese speakers. The discrimination
task was to listen to a series of three sounds, and make note of which of the
three was different. The results showed that the Americans could easily
discriminate the target sound, only getting low scores if the sounds were
ambiguous as to if it was /r/ or /l/, <em>“pairs whose members were labeled as the
same phoneme was considerable less accurate, although still above the 33% chance
level”</em> (Miyawaki, et al. 1975). The Japanese however, showed a near-chance
level of discrimination. An interesting aspect of this study was the finding
that when speech sound context was not included, the two groups behaved almost
identically, <em>“we see very clearly that the Japanese do not differ from the
Americans on any of the comparison pairs. The nonspeech discrimination functions
are virtually identical for the two groups of subjects.”</em> (Miyawaki, et at.,
1975). Both groups were able to discriminate isolated F3 patterns quite
accurately, which indicates that both groups are able to hear sound differences
physical sub-contextual level.</p>
<p>A later study on the /r/ and /l/ perception task using a synthetic speech
generation process similar to the above study focused on if linguistic
experience had an impact on categorical perception of the /r/ and /l/ phonemes.
They were suggesting that <em>“... native Japanese adults learning English as a
second language are capable of categorical perception of /r/ and l/l.”</em>
(MacKain, et al., 1981). This study was similar to the above, but had a few
differences. The first was how they varied the acoustic values both temporally
and spectrally <em>“to optimize the Japanese subjects’ opportunity to show
perceptual differentiation of the /r/-/l/ contrast.”</em> (MacKain, et al., 1981).
The second was the inclusion of an AXB oddity discrimination task which is
thought to provide a better opportunity to let the subjects detect auditory
differences. The third was an identification task for both the American and
Japanese groups. The Americans, as expected, displayed a strong category
boundary with strong identification scores. The not-experienced Japanese
subjects displayed poor categorization of the /r/ and /l/ with near chance
levels in all stimuli types. The results in the non-experienced Japanese group
extended the Miyawaki results. The experienced group <em>“had intensive English
conversation training with native American-English speakers and as a group spent
a larger percentage of the average day conversing in English than did the
not-experienced Japanese.”</em> (MacKain, et at., 1981). This group displayed
similar results to the Americans on both the identification tasks and the
discrimination tasks. These results suggests <em>“that the occurrence and
abruptness of an /r/-/l/ category boundary for the experience Japanese might be
related to their grater conversational English experience…”</em> (MacKain et al.,
1981). This particular study had added the AXB oddity task because it is less
memory demanding and <em>“they could use nonphoenetic auditory memory to aid
performance”</em> (MacKain et al., 1981) in the hopes that it would allow the
non-experienced Japanese to obtain better results, but this particular task did
not achieve the hopes of its design intentions. Overall, their research
suggested that Japanese native speakers can obtain categorical perception of /r/
and /l/ with some practice and more experience, which is good news to aspiring
bilinguals.</p>
<p>Research into the /r/ and /l/ phonemes is interesting particularly to Japanese
because of the lack of contrast between these sounds. Distinctive contrast in
particular speech sounds allows speakers of that language to discriminate where
other language speakers would not. The above studies examined this aspect as
well, but in a 1984 study by Strange and Dittmann focused on how the ability to
discriminate sounds not available in the L1 can change with explicit training,
<em>“We were interested in whether we could modify the perception of AE
word-initial /r/ and /l/ by adult Japanese learners of English, in the
laboratory, using the psychophysical training task successfully employed by
Carney et al. (1977).”</em> (Strange &amp; Dittmann, 1984). The design of this study was
to test the abilities of eight female Japanese native speakers before training
and then again after training to examine the effects of training on
discrimination of the /r/ and /l/ series of synthetic speech sounds. The initial
pre-training tests consisted of a minimal pairs test, an identification of the
rock-lock series and an oddity discrimination task. The training was done
individually over a three week period that totaled 14 to 18 sessions, it
consisted of an AX discrimination task with immediate feedback. At the end of
the training the post-training tests were given, which were the same as the
pre-training tests. Pre-training results were similar to the results found in by
MacKain in 1981, with near-chance levels of accuracy. The training task
performance showed <em>“gradual improvement over session with the greatest
improvement in the first several sessions”</em> (Strange &amp; Dittmann, 1984). All
subjects showed increased performance as the training sessions progressed. After
the training, the post-training tests showed that <em>“pretraining versus
posttraining categorical perception tests for each of the eight subjects of the
rock-lock series revealed that seven of the eight subjects improved as a
function of the training.”</em> (Strange &amp; Dittmann, 1984). Post-training test
results also showed improvement in their discrimination of cross-category pairs
with over 75% correct (Strange &amp; Dittmann, 1984). Overall, training did indicate
improvement as performance on post-training tests showed better performance
results (Strange &amp; Dittmann, 1984). <em>“We can thus conclude that training with a
fixed-standard AX discrimination task resulted in improved (categorical)
perception of the training stimuli, as tested by the (more demanding)
identification and oddity discrimination tasks”</em> (Strange &amp; Dittmann, 1984).
This study also tested differences in sound according to acoustic properties.
They wanted to test if training in the /rock/ - /lock/ set would transfer over
to good performance in a similar /rake/ - /lake/ test. Their results showed that
it was indeed the case, and training did help this test achieve improved
performance, this also supports the idea that bilinguals can indeed learn to
perceive new sounds in a second language.</p>
<h3>2. Speech segmentation using the Mora</h3>
<p>One of the major differences in a language is how it is timed, or the rhythm of
the language. Bilinguals not only have to learn a new lexicon and grammar
system, but sometimes must also learn a new rhythm to speak their L2. An example
of this would be a native English speaker trying to learn Japanese or
vise-versa. English is a stress-timed language whereas Japanese is mora-timed.
Research of the mora can help lead to further understanding of how languages of
different timing style can be learned more efficiently for bilinguals as well as
how differences in timing can affect different aspects of speech segmentation.</p>
<p>In a study by Otake et al., 1993, of how Japanese words are segmented by native
and non-native listeners, results found that Japanese responses were consistent
with moraic segmentation, while non-native listeners responded differently. The
mora is a uniquely Japanese timing mechanism; it is smaller than a syllable, and
is considered the basic unit of perception. This study set up four experiments
with native and non-native speakers to examine the effects of native timing type
on Japanese words. In the first experiment 40 native Japanese speakers were used
to listen to a series of 3 to 6 words. When a word was heard with the target
letters on a printed card, the subject was to press a button. Results showed
that the native Japanese listeners responses better supported the mora
hypothesis than the syllable hypotheses, confirming their initial hypothesis
that Japanese speakers will segment words best with the mora-timed segmentation
style. <em>“The pattern of results in this experiment thus appears to offer strong
support for the mora hypothesis but none to the syllable hypothesis.”</em> (Otake et
al, 1993). The second experiment tested English speaking subjects on Japanese
words. The design was similar to the previous task on the Japanese subjects,
where a series of Japanese words would be played, and the subject was to press a
button once the sound on the printed card was heard. The results of this
experiment are in stark contrast with that of experiment 1. The findings in this
experiment support that <em>“we many now conclude that English listeners do not
exploit mora structure in the same way.”</em> (Otake et al., 1993) [as Japanese
native listeners]. A note about experiment 1, the targets were presented on
printed card in Roman text orthography, this can introduce confounds due to how
Japanese naturally represent sounds with kana characters. Experiment 3 was
exactly the same design as experiment 1 with the exception that the target word
was played through the headphones before the word sequence rather than being
printed on a card. Experiment 3 had 40 native Japanese speaking subjects. The
target sound was played first, followed by the sequences of test words. The
subject would press a button when they heard the target word in the sequence.
The results of experiment 3 replicated those of experiment 1. <em>“The replication
of experiment 1’s results strongly confirms our conclusions from the preceding
experiments: Japanese listeners do not naturally segment speech syllable by
syllable; they do naturally segment it mora by mora.”</em> (Otake et al., 1993).
These findings also cleared up the problem of orthography of Japanese speech
sounds mentioned earlier. Experiment 4 was identical to experiment 3 with the
exception of the subjects being 33 native French speakers. The results of
experiment 4 were as expected, <em>“the response patterns of French listeners are,
as predicted, best accounted for by the syllabic hypothesis…”</em> (Otake et al.,
1993). These results also support findings by Cutler et al., 1986. Finally,
these results support the predictions made initially, that non-native listeners
will <em>“not replicate the pattern of results shown with the same materials by
native Japanese listeners”</em> (Otake et al., 1993). These results support that
non-native listeners will try to segment the sounds of a non-native language by
applying their native speech segmentation system, whether its mora-based,
stress-based or syllable-based. How could that affect learning a second language
where the segmentation process is different from the native language?</p>
<p>Taking from some of the findings from the previous study, Cutler and Otake
started a new research project in 1994 that would focus on whether subjects
would apply their native segmentation processes to a foreign language. This
research could show that inappropriate use of a segmentation process could
inhibit the processing of a non-native language in bilinguals. <em>“This suggests
that segmentation procedures may indeed be highly similar to phonological
categorization procedures: they effectively aid processing of the native
language, but they may reduce processing efficiency for input in a foreign
language.”</em> (Cutler &amp; Otake, 1994). This study also hoped to further support the
mora hypothesis put forth by Otake in 1993. The first experiment was to test
Japanese native speakers on if moraic targets <em>“will be easier to detect than
nonmoraic”</em> (Cutler &amp; Otake, 1994). This should prove to be the case under the
mora hypothesis. This experiment will also test for whether phoneme detection
<em>“will be differentially difficult for vowels versus consonants”</em> (Cutler &amp;
Otake, 1994). Experiment 1 was designed with 40 native Japanese speakers, they
would listen for a target sound (O or N) in a series of Japanese words, and
press a response key as soon as they detected the sound. The results from this
experiment showed the same results seen in Otake (1993): <em>“mora structure is
crucially involved in the process by which Japanese listeners convert spoken
input in lexically accessible representation.”</em> (Cutler &amp; Otake, 1993), as well
as showing that quick responses to moraic input is not only restricted to CV
input as seen in Otakes’ 1993 experiment. It should be noted that there were no
significant findings concerning the differences in vowel and consonant response
times mentioned earlier. Experiment 2 was conducted in the same way as
experiment 1, with the exception that the subjects were 24 English native
speakers. As expected, the non-native speakers did not demonstrate the moraic
effects shown in experiment 1. Interestingly, <em>“The main effect of vowel versus
consonant target was, however, significant; consonants were detected both faster
and more accurately than vowels”</em> (Cutler &amp; Otake, 1994). This supports the
earlier findings that native listeners apply their native segmentation
procedures to a non-native language. Experiment 3 was similar to experiment 2
except with English words as both target and sequence words. The subjects were
24 native English speakers. Findings in experiment 3 showed that <em>“These
findings are in line with previous failures to find significant phoneme
detection differences between targets in stressed versus unstressed position
with English listeners and laboratory-read speech.”</em> (Cutler &amp; Otake, 1994).
These results were similar to experiment 2. Experiment 4 used the same materials
as experiment 3, English words, while it used the same design, as well as the
same subjects as in experiment 1, using Japanese native speakers. Results in
this experiment found the vowel sounds were much more difficult to find than the
consonantal targets (Cutler &amp; Otake, 1994). The findings of experiment 4 also
help support the mora hypothesis, namely <em>“that mismatch between in the input
and the native language phonemic repertoire plays a role in phoneme detection in
a foreign language.”</em> (Cutler &amp; Otake, 1994). Experiment 5 was designed with 20
native Japanese speakers listening to a played back words of native Japanese.
The procedure was that of experiment 1. The subjects were to press a button when
they heard a target phoneme in the played back word sequence. The results of
this experiment demonstrated what the experimenters had hoped for, <em>“a new
effect in Japanese phoneme-monitoring: targets in word-initial position are
detected faster than targets in word-medial position.”</em> (Cutler &amp; Otake, 1994).
This experiment showed the mora effect was significant for all four phoneme
targets. Experiment 6 involved doing the same as experiment 5 but with English
subjects. This experiment was designed to show the English speakers advantage of
detection of vowels over consonant targets, as well as observing a difference in
RTs in A and O due to <em>“phoneme repertoire mismatch”</em> (Cutler &amp; Otake, 1994).
This experiment used the same materials in experiment 5 with 23 native English
speakers using the procedures from experiment 2. The results of this experiment
showed that <em>“there was again a significant overall advantage for consonant over
vowel targets”</em> (Cutler &amp; Otake, 1994). Overall these experiments had shown that
the <em>“the moraic effect which Japanese listeners show in phoneme detection in
their native language appears in world-initial well as in word-medial position
and with a variety of phoneme targets.”</em> (Cutler &amp; Otake, 1994). These
experiments also go to explain that the consonant and vowel detection abilities
of English speakers appear when listening to Japanese, due to native English
segmentation process advantages in this particular task.</p>
<p>In terms of bilinguals, the above studies used Japanese native speakers, some of
whom had some English experience. Even with experience, it was shown that they
were still applying mora segmentation to English input, as well as English
speakers applying stress-based segmentation when it is inappropriate in Japanese
input. As quoted from the above study <em>“We believe that this finding has
potentially important implication for understanding the processes of acquisition
of a second language.”</em> (Cutler &amp; Otake, 1994). Although this research seems to
cast a dim picture on those trying to learn a second language, all is not lost,
in a study by Cutler et al., 1992, showed that more than one segmentation
process is available, and even if not available, these rhythm based processes
are heuristics for processing a non-native language, are not necessary for
comprehension. (Cutler et al., 1992).</p>
<h3>3. Rhythmic cues and the Lexicon</h3>
<p>An important area of study is on how rhythmic cues in the speech stream affect
lexical decisions in Japanese. A learner of Japanese would be affected by this
in that many languages don’t use rhythmic cues, and so in learning Japanese,
rhythmic cues may not serve as an available heuristic. Japanese provides a good
test platform to study rhythmic cues and speech segmentation because Japanese
<em>“rhythm is based neither on syllables nor on stress. Instead, it is based on
the mora, a subsyllabic unit which can be of five different types”</em> (McQueen et
al, 2001).</p>
<p>In a study by Cutler and Otake, examining old Japanese wood-block prints which
contained a word-based joke system called “Goroawase” to examine if there
existed sub-moraic information processing in the speech stream. This joke system
is used by substituting a single mora in a word with another mora to create a
similar sounding word with a different meaning, thus creating a word-pun. Their
findings suggest that <em>“mora substitution is more often than would be expected
by chance in effect phoneme substitution because two words which overlap in all
but a single consonant or vowel form a better target-pun pair than two words
which overlap in all but a CV mora.”</em> (Cutler &amp; Otake, 2002). Another experiment
in the same paper uses word reconstruction. They had subjects listen to a word
with a replaced mora, and were told which mora was changed. The subjects were
then to tell which word had been intended. This experiment would use mora as the
cue to the target word, which would then be accessed via the lexicon. 45 native
Japanese speaking subjects partook in this experiment and the results were as
expected. 4 mora words were more easily accessed than 3 mora words. Their
results suggested that <em>“word reconstruction was significantly easier when the
initial mora had been replaced by another mora sharing with it either C or V.”</em>
(Cutler &amp; Otake, 2002). In their second experiment, they distorted the final
mora of the word, and found that identification was faster and more accurate,
which suggests <em>“that this information can be exploited continuously rather than
only on a mora-by-mora basis”</em> (Cutler &amp; Otake, 2002). This indicates that
lexical access can occur without complete moraic information. In experiments 3
and 4 of their research, they tested replacing both third and fourth mora and
placed a focus on consonant versus vowel replacement, they found similar results
to experiment two. <em>“Although both the V-replacement and C-replacement condition
proved easier than M-replacements, there was also a difference between the first
two: Replacement of a vowel proved easier than replacement of a consonant.”</em>
(Cutler &amp; Otake, 2002). On their 5th experiment, they used a Yes/No type
response to the design of the previous experiment, their results helped to
cement their conclusion that there is continuous speech processing, even below
the level of the mora. (Cutler &amp; Otake, 2002). This does not suggest that there
is no mora, but only that continuous speech sounds are helpful to the
segmentation of the continuous speech stream (Cutler &amp; Otake, 2002). Their
results do however suggest, and support the findings of Norris et al., in 1997,
<em>“that the contribution of rhythmic categories in word recognition is the same
for all languages”</em> (Cutler &amp; Otake, 2002). As rhythmic categories are universal
to all languages (Norris et al., 1997), this would provide some relief to
learners of Japanese a second language, as mora are not the end-all to
segmentation, but a heuristic function that helps to make segmentation more
efficient.</p>
<p>If mora and meter are both parts of speech segmentation, how can we combine the
two? A study by McQueen, Otake and Cutler in 2001 tries to answer that. Their
experiments use the PWC, or Possible Word Constraint developed by Norris et al.,
in 1997 to test if Japanese speakers use the PWC just as English and Dutch
speakers. The PWC is another type of heuristic function used in speech
segmentation particular to the Shortlist model developed by Norris et al.,
(1997). Their first experiment used 54 native Japanese speakers to listen to a
native speaker of Japanese pronounce nonwords with Japanese words embedded
within them. The subjects were then to press a button and pronounce the embedded
word once they heard it. The results of the experiment showed that indeed,
<em>“listeners find it harder to spot words in impossible word contexts than in
possible word contexts. Japanese listeners therefore appear to use the PWC when
segmenting speech.”</em> (McQueen, Otake &amp; Cutler, 2001). Other tests done in this
study all supported the PWC and show similar results done with English speakers.
(McQueen, Otake &amp; Cutler, 2001). The PWC suggests the speech segmentation is
more universal than previously devised models. This model suggests that words
are activated and no particular lexical decision is 100% decided, until all are
decided. <em>“The present experiments therefore support the theory of lexical
segmentation that the PWC offers. On this view, candidate words are activated by
the incoming speech stream and compete with each other until a lexical parse is
settled upon.”</em> (McQueen, Otake &amp; Cutler, 2001). This model also allows for the
rhythmic segmentation process to exist and help add to the parsing of lexical
and segmental structure. <em>“Furthermore, just as the rhythmic structure of
English or Dutch provides English and Dutch listeners with cues to the location
of likely word boundaries (Cutler &amp; Norris, 1988, Vroomen et at., 1996), so too
does the characteristic rhythm of Japanese provide Japanese listeners with a
segmentation cue.”</em> (McQueen, Otake &amp; Cutler, 2001).</p>
<p>Rhythmic segmentation provides another type of segmentation heuristic along with
mora-based segmentation as seen in the above papers. Although bilinguals have
trouble when inappropriately applying their native language segmentation style
to a non-native language, rhythmic segmentation is a universal heuristic which
exists to compensate when L1 segmentation style fails to properly segment the
non-native language.</p>
<h3>4. Segmentation in non-native languages</h3>
<p>An important area of study concerning bilingual speech segmentation is how
non-native speakers segment their second language (L2). If non-native speakers
can use any of the non-native language rhythmic, prosodic, lexico-syntatic, and
syntactic segmentation processes, then they will have a much easier time
segmenting the L2. The ability to learn a non-native segmentation process would
be beneficial to any bilingual as it would facilitate comprehension of the L2.
Research into brain plasticity for learning non-native language processes would
directly benefit the existing body of knowledge.</p>
<p>In a study of brain plasticity and non-native lexical and segmentation
processes, Sanders et al. in 2002 came up with interesting methods for probing
non-native speakers to see if learning the L2 early in life or later in life
would effect the ability to learn non-native lexical and segmentation processes.
This study would research various language subsystems such as lexico-semantic,
syntactic, and prosodic information processing. Using the earlier proposed
theories that each language uses different methods of speech segmentation
(English: Stress-based, French: Syllable-based, Japanese: Mora-based) they tried
to find if non-native speakers used lexico-syntactic information processes when
segmenting a non-native language (Sanders et al., 2002). Four groups were
obtained to study this hypothesis, a group of native English speakers as a
control group (E), early English Japanese native speakers (JE), early English
Spanish native speakers (SE), late English Japanese native speakers (J), and a
group of late English Spanish native speakers (S). <em>“If non-native speakers fail
to use rhythmic segmentation cues other than the rhythmic cues relevant to their
L1, native speakers of Japanese (mora-timed) and Spanish (syllable-timed) would
not be expected to use stress pattern as a segmentation cue when listening to
English. Alternatively, native Japanese and native Spanish speakers might differ
in their abilities to use stress pattern as a segmentation cue in English.”</em>
(Sanders et al., 2002). For this experiment they created 5 groups of 3 sentences
each. The 5 groups were <em>“Strong stress, initial position (SI), strong stress,
medial position (SM), weak stress, initial position (WI), weak stress, medial
position (WM), and target absent (TA).”</em> (Sanders et al., 2002). Each group
contained 3 sentences each of which were a semantic, syntactic or acoustic
target sentence. The semantic words were normal English sentences, the syntactic
sentences replaced all open-class words with non-words, and the acoustic words
only retained the original prosody. Participants were asked to listen to a
target, and then were asked to press one button if that target was heard in the
beginning of the sentence, another button if it was heard in the middle, and the
third button if it was not heard. Results indicated that <em>“the fact that both
groups of late-learners were able to use the lexical information supports the
hypothesis that the lexico-semantic system remains relatively plastic beyond the
age of 12.”</em> (Sanders et al., 2002). These results support the idea that late
learners can learn non-native language processes later in life, which is a
reassuring fact for late-bilinguals, however <em>“No group of non-native speakers
used syntactic information to the same extent as native speakers.”</em> (Sanders et
al., 2002). These results, as well as other indicate that syntactic information
processes are not as easily learned later in life (Sanders et al., 2002). An
interesting finding was how both early and late learners of English
Japanese-natives were able to use some segmentation cues that are seemingly
effective in both English and Japanese; <em>“this study could either indicate that
both groups were applying a Japanese segmentation cue that happens to co-occur
with stress in English or that both groups had enough exposure to English to
learn a new segmentation cue.”</em> (Sanders et al., 2002). Overall the findings of
this study show that both lexical and semantic segmentation subsystems retain
the <em>“ability to change to a greater degree than do syntactic subsystems”</em>
(Sanders et al., 2002).</p>
<p>In terms of bilinguals, some very reassuring findings from the above study is
that some segmentation processes are still learnable later in life, and they are
also interchangeable, one or more can be used when another is unavailable or not
applicable. <em>“The findings also indicate that segmentation cues can be used
flexibly by both native and non-native speakers, such that cues that are both
available in the speech stream and usable by the listener are employed to a
greater extent when other segmentation cues are either absent or not accessible
to the listener.”</em> (Sanders et al., 2002).</p>
<h2>III. Possible directions for future research</h2>
<p>In studies such as Otake (1993), findings were made that support the idea that
non-native speakers segment a foreign language using their native segmentation
processes. Future research could focus on bilinguals learning an L2 that has a
totally different segmentation process. An example would be how a Japanese
learning English or an American learning French begins to learn a new
segmentation style, and how specific training on segmentation may make learning
more efficient. A similar study design that could be used would be Strange &amp;
Dittmanns’ (1984) study on the /r/ - /l/ distinction of Japanese speaking
English. This study could be applied to learning a new segmentation style. The
time of acquisition of a new non-native speech segmentation process would also
be of interest to this field. Also of interest to future research is the topics
of multiple segmentation cues, such as lexico-semantic, and prosody, and how
these can be used interchangeably along with more native segmentation processes
such as mora, syllable, or stress-based segmentation.</p>
<h2>References</h2>
<cite class="hanging-indent"><p>Beckman, M. (1982). Segment Duration and the ‘Mora’ in Japanese. <em>Phonetica</em>,
39, 113-135.</p></cite>
<cite class="hanging-indent"><p>Cutler, A., &amp; Butterfield, S. (1992). Rhythmic cues to speech segmentation:
Evidence from juncture misperception. <em>Journal of Memory and Langauge</em>, 31,
218-236.</p></cite>
<cite class="hanging-indent"><p>Cutler, A., Mehler, J., Norris, D., Segui, J., (1986). The Syllable’s Differing
Role in the Segmentation of French and English. <em>Journal of Memory and
Language</em>, 25, 385-400.</p></cite>
<cite class="hanging-indent"><p>Cutler, A., &amp; Norris, D. (1988). The role of strong syllables in segmentation
for lexical access. <em>Journal of Experimental Psychology: Human Perception and
Performance</em>, 14, 113-121.</p></cite>
<cite class="hanging-indent"><p>Cutler, A., Otake, T. (2002). Rhythmic Categories in Spoken-Word Recognition.
<em>Journal of Memory and Language</em>, 46, 296-322.</p></cite>
<cite class="hanging-indent"><p>Cutler, A., Otake, T. (1994). Mora or Phoneme? Further Evidence for
Langauge-Specific Listening. <em>Journal of Memory and Language</em>, 33, 824-844.</p></cite>
<cite class="hanging-indent"><p>Goto, H. (1971). Auditory perception by normal Japanese adults of the sounds “L”
and “R”. <em>Neuropsychologia</em>, 9, 317-323.</p></cite>
<cite class="hanging-indent"><p>MacKain, K. S., Best, C. T., Strange, W. (1981). Categorical perception of
English /r/ and /l/ by Japanese bilinguals. <em>Applied Psycholinguistics</em>, 2,
369-390.</p></cite>
<cite class="hanging-indent"><p>McQueen, M. J., Otake, T., Cutler, A., (2001). Rhythmic Cues and Possible-Word
Constraints in Japanese Speech Segmentation. <em>Journal of Memory and Language</em>,
45, 103-132.</p></cite>
<cite class="hanging-indent"><p>Miyawaki, K., Strange, W., Verbrugge, R., Liberman, A. M., Jenkins, J. J.,
Fujimura, O. (1975). An effect of linguistic experience: The discrimination of
[r] and [l] by native speakers of Japanese and English, <em>Perception &amp;
Psychophysics</em>, 18, 331-340.</p></cite>
<cite class="hanging-indent"><p>Norris, D. G., McQueen, J. M., Cutler, A., &amp; Butterfield, S. (1997). The
possible-word constraint in the segmentation of continuous speech. <em>Cognitive
Psychology</em>, 34 191-243</p></cite>
<cite class="hanging-indent"><p>Otake, T., Hatano, G., Cutler, A., Mehler, J., (1993) Mora or Syllable? Speech
Segmentation in Japanese. <em>Journal of Memory and Language</em>, 32, 258-278.</p></cite>
<cite class="hanging-indent"><p>Sanders, L. D., Neville, H. J., Woldorff, M. G., (2002). Speech Segmentation by
Native and Non-Native Speakers: The Use of Lexical, Syntactic, and
Stress-Pattern Cues. <em>Journal of Speech, Language, and Hearing Research</em>, 45,
519-530.</p></cite>
<cite class="hanging-indent"><p>Strange, W., Dittmann, S., (1984).
Effects of discrimination training on the
perception of /r-l/ by Japanese adults learning English.
<em>Perception &amp; Psychophysics</em>,
36(2), 131-145.</p></cite></div><footer class="license_copyright__EpMnZ">This is licensed under a Creative Commons <!-- -->cc-by-nc-sa<!-- --> International License</footer></article></main><footer class="footer_footer__woFMY layout_layout__dCqca"><nav><p>© 2003-<!-- -->2024<!-- --> 0xADADA (unless otherwise noted.)<br/><a title="0xADADA" href="/">Home</a> <span class="h-card"><a class="c-Meta u-email" rel="me" title="0xADADA" href="mailto:0xadada.pub@protonmail.com">Email</a> </span><a rel="me nofollow external noopener" title="0xADADA on Warpcast" href="https://warpcast.com/0xadada">Farcaster</a> <a rel="me nofollow external noopener" title="0xADADA on Mastodon" href="https://mastodon.cloud/@0xADADA">Mastodon</a> <a rel="me nofollow external noopener" title="0xADADA on Bluesky" href="https://bsky.app/profile/0xadada.bsky.social">Bluesky</a> <a rel="me nofollow external noopener" title="0xADADA on Twitter" href="https://twitter.com/0xadada">Twitter</a> <a rel="me nofollow external noopener" title="0xADADA on GitHub" href="https://github.com/0xadada">GitHub</a> <a rel="me nofollow external noopener" title="0xADADA on Goodreads" href="https://www.goodreads.com/review/list/60524683-0xadada?shelf=wanted">Goodreads</a> <a href="/rss.xml">RSS</a> <img src="/static/images/meta/avatar.svg" alt="0xADADA icon" width="20" style="margin-bottom:-0.125rem"/></p></nav></footer><script src="/_next/static/chunks/webpack-bb5b7c6ade2286d3.js" crossorigin="" async=""></script><script>(self.__next_f=self.__next_f||[]).push([0]);self.__next_f.push([2,null])</script><script>self.__next_f.push([1,"1:HL[\"/_next/static/css/32a94118522b884a.css\",\"style\",{\"crossOrigin\":\"\"}]\n0:\"$L2\"\n"])</script><script>self.__next_f.push([1,"3:HL[\"/_next/static/css/ec967fd209f0dd40.css\",\"style\",{\"crossOrigin\":\"\"}]\n"])</script><script>self.__next_f.push([1,"4:I[7690,[],\"\"]\n7:I[5613,[],\"\"]\nc:I[1778,[],\"\"]\nd:I[5250,[\"250\",\"static/chunks/250-d7e0a94ebe194dac.js\",\"931\",\"static/chunks/app/page-f7ba098afe402509.js\"],\"\"]\nf:I[8955,[],\"\"]\n8:[\"year\",\"2003\",\"d\"]\n9:[\"month\",\"12\",\"d\"]\na:[\"date\",\"14\",\"d\"]\nb:[\"slug\",\"speech-segmentation-in-japanese-and-english-bilinguals\",\"d\"]\n10:[]\n"])</script><script>self.__next_f.push([1,"2:[[[\"$\",\"link\",\"0\",{\"rel\":\"stylesheet\",\"href\":\"/_next/static/css/32a94118522b884a.css\",\"precedence\":\"next\",\"crossOrigin\":\"\"}]],[\"$\",\"$L4\",null,{\"buildId\":\"OKvUWDrFVfsGmxcrVdor5\",\"assetPrefix\":\"\",\"initialCanonicalUrl\":\"/2003/12/14/speech-segmentation-in-japanese-and-english-bilinguals/\",\"initialTree\":[\"\",{\"children\":[[\"year\",\"2003\",\"d\"],{\"children\":[[\"month\",\"12\",\"d\"],{\"children\":[[\"date\",\"14\",\"d\"],{\"children\":[[\"slug\",\"speech-segmentation-in-japanese-and-english-bilinguals\",\"d\"],{\"children\":[\"__PAGE__?{\\\"year\\\":\\\"2003\\\",\\\"month\\\":\\\"12\\\",\\\"date\\\":\\\"14\\\",\\\"slug\\\":\\\"speech-segmentation-in-japanese-and-english-bilinguals\\\"}\",{}]}]}]}]}]},\"$undefined\",\"$undefined\",true],\"initialSeedData\":[\"\",{\"children\":[[\"year\",\"2003\",\"d\"],{\"children\":[[\"month\",\"12\",\"d\"],{\"children\":[[\"date\",\"14\",\"d\"],{\"children\":[[\"slug\",\"speech-segmentation-in-japanese-and-english-bilinguals\",\"d\"],{\"children\":[\"__PAGE__\",{},[\"$L5\",\"$L6\",null]]},[\"$\",\"$L7\",null,{\"parallelRouterKey\":\"children\",\"segmentPath\":[\"children\",\"$8\",\"children\",\"$9\",\"children\",\"$a\",\"children\",\"$b\",\"children\"],\"loading\":\"$undefined\",\"loadingStyles\":\"$undefined\",\"loadingScripts\":\"$undefined\",\"hasLoading\":false,\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$Lc\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":\"$undefined\",\"notFoundStyles\":\"$undefined\",\"styles\":[[\"$\",\"link\",\"0\",{\"rel\":\"stylesheet\",\"href\":\"/_next/static/css/ec967fd209f0dd40.css\",\"precedence\":\"next\",\"crossOrigin\":\"\"}]]}]]},[\"$\",\"$L7\",null,{\"parallelRouterKey\":\"children\",\"segmentPath\":[\"children\",\"$8\",\"children\",\"$9\",\"children\",\"$a\",\"children\"],\"loading\":\"$undefined\",\"loadingStyles\":\"$undefined\",\"loadingScripts\":\"$undefined\",\"hasLoading\":false,\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$Lc\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":\"$undefined\",\"notFoundStyles\":\"$undefined\",\"styles\":null}]]},[\"$\",\"$L7\",null,{\"parallelRouterKey\":\"children\",\"segmentPath\":[\"children\",\"$8\",\"children\",\"$9\",\"children\"],\"loading\":\"$undefined\",\"loadingStyles\":\"$undefined\",\"loadingScripts\":\"$undefined\",\"hasLoading\":false,\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$Lc\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":\"$undefined\",\"notFoundStyles\":\"$undefined\",\"styles\":null}]]},[\"$\",\"$L7\",null,{\"parallelRouterKey\":\"children\",\"segmentPath\":[\"children\",\"$8\",\"children\"],\"loading\":\"$undefined\",\"loadingStyles\":\"$undefined\",\"loadingScripts\":\"$undefined\",\"hasLoading\":false,\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$Lc\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":\"$undefined\",\"notFoundStyles\":\"$undefined\",\"styles\":null}]]},[null,[\"$\",\"html\",null,{\"lang\":\"en-US\",\"children\":[\"$\",\"body\",null,{\"children\":[[\"$\",\"main\",null,{\"className\":\"layout_layout__dCqca\",\"children\":[\"$\",\"$L7\",null,{\"parallelRouterKey\":\"children\",\"segmentPath\":[\"children\"],\"loading\":\"$undefined\",\"loadingStyles\":\"$undefined\",\"loadingScripts\":\"$undefined\",\"hasLoading\":false,\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$Lc\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":[[\"$\",\"title\",null,{\"children\":\"404: This page could not be found.\"}],[\"$\",\"div\",null,{\"style\":{\"fontFamily\":\"system-ui,\\\"Segoe UI\\\",Roboto,Helvetica,Arial,sans-serif,\\\"Apple Color Emoji\\\",\\\"Segoe UI Emoji\\\"\",\"height\":\"100vh\",\"textAlign\":\"center\",\"display\":\"flex\",\"flexDirection\":\"column\",\"alignItems\":\"center\",\"justifyContent\":\"center\"},\"children\":[\"$\",\"div\",null,{\"children\":[[\"$\",\"style\",null,{\"dangerouslySetInnerHTML\":{\"__html\":\"body{color:#000;background:#fff;margin:0}.next-error-h1{border-right:1px solid rgba(0,0,0,.3)}@media (prefers-color-scheme:dark){body{color:#fff;background:#000}.next-error-h1{border-right:1px solid rgba(255,255,255,.3)}}\"}}],[\"$\",\"h1\",null,{\"className\":\"next-error-h1\",\"style\":{\"display\":\"inline-block\",\"margin\":\"0 20px 0 0\",\"padding\":\"0 23px 0 0\",\"fontSize\":24,\"fontWeight\":500,\"verticalAlign\":\"top\",\"lineHeight\":\"49px\"},\"children\":\"404\"}],[\"$\",\"div\",null,{\"style\":{\"display\":\"inline-block\"},\"children\":[\"$\",\"h2\",null,{\"style\":{\"fontSize\":14,\"fontWeight\":400,\"lineHeight\":\"49px\",\"margin\":0},\"children\":\"This page could not be found.\"}]}]]}]}]],\"notFoundStyles\":[],\"styles\":null}]}],[\"$\",\"footer\",null,{\"className\":\"footer_footer__woFMY layout_layout__dCqca\",\"children\":[\"$\",\"nav\",null,{\"children\":[\"$\",\"p\",null,{\"children\":[\"© 2003-\",\"2024\",\" 0xADADA (unless otherwise noted.)\",[\"$\",\"br\",null,{}],[\"$\",\"$Ld\",null,{\"href\":\"/\",\"title\":\"0xADADA\",\"children\":\"Home\"}],\" \",[\"$\",\"span\",null,{\"className\":\"h-card\",\"children\":[[\"$\",\"$Ld\",null,{\"href\":\"mailto:0xadada.pub@protonmail.com\",\"className\":\"c-Meta u-email\",\"rel\":\"me\",\"title\":\"0xADADA\",\"children\":\"Email\"}],\" \"]}],[\"$\",\"$Ld\",null,{\"href\":\"https://warpcast.com/0xadada\",\"rel\":\"me nofollow external noopener\",\"title\":\"0xADADA on Warpcast\",\"children\":\"Farcaster\"}],\" \",[\"$\",\"$Ld\",null,{\"href\":\"https://mastodon.cloud/@0xADADA\",\"rel\":\"me nofollow external noopener\",\"title\":\"0xADADA on Mastodon\",\"children\":\"Mastodon\"}],\" \",[\"$\",\"$Ld\",null,{\"href\":\"https://bsky.app/profile/0xadada.bsky.social\",\"rel\":\"me nofollow external noopener\",\"title\":\"0xADADA on Bluesky\",\"children\":\"Bluesky\"}],\" \",[\"$\",\"$Ld\",null,{\"href\":\"https://twitter.com/0xadada\",\"rel\":\"me nofollow external noopener\",\"title\":\"0xADADA on Twitter\",\"children\":\"Twitter\"}],\" \",[\"$\",\"$Ld\",null,{\"href\":\"https://github.com/0xadada\",\"rel\":\"me nofollow external noopener\",\"title\":\"0xADADA on GitHub\",\"children\":\"GitHub\"}],\" \",[\"$\",\"$Ld\",null,{\"href\":\"https://www.goodreads.com/review/list/60524683-0xadada?shelf=wanted\",\"rel\":\"me nofollow external noopener\",\"title\":\"0xADADA on Goodreads\",\"children\":\"Goodreads\"}],\" \",[\"$\",\"$Ld\",null,{\"href\":\"/rss.xml\",\"children\":\"RSS\"}],\" \",[\"$\",\"img\",null,{\"src\":\"/static/images/meta/avatar.svg\",\"alt\":\"0xADADA icon\",\"width\":\"20\",\"style\":{\"marginBottom\":\"-0.125rem\"}}]]}]}]}]]}]}],null]],\"initialHead\":[false,\"$Le\"],\"globalErrorComponent\":\"$f\",\"missingSlots\":\"$W10\"}]]\n"])</script><script>self.__next_f.push([1,"11:T471,"])</script><script>self.__next_f.push([1,"\n(Otake, Hatano, Cutler \u0026 Mehler, 1993). Japanese is a “mora-timed” language,\nwhere each mora represents a rhythmic unit; in comparison to English which is\n“stress-timed” (Beckman, 1982). There has been much research into the field of\nspeech segmentation, specifically into the types listed above including\nstressed-base and syllable-based (Cutler, Mehler, Norris \u0026 Segui, 1986), as well\nas mora-based (Cutler \u0026 Otake, 1994). There has also been a fair amount of study\non phoneme discrimination of /r/ and /l/ in native speakers of Japanese and\nEnglish. One particular study (Miyawaki, Strange \u0026 Verbrugge, Liberman, Jenkins\n\u0026 Fujimura, 1975) used synthesized speech to compare Americans and Japanese at\ndiscriminating /ra/ and /la/. A follow-up study a few years later reinforced\nprevious findings that Americans can categorically discriminate the phonemes,\nand that Japanese are at a near-chance level of perception (Strange \u0026 Dittmann,\n1984). This study also showed that after training, the native Japanese\nperformance on those phones increased, and therefore categorical perception is\nindeed possible for non-native speakers."])</script><script>self.__next_f.push([1,"12:T45a,"])</script><script>self.__next_f.push([1," (Miyawaki et al., 1975). The /r/ and /l/ phones don’t constitute a\nphonemic contrast in Japanese, and therefore would provide a good base to\nconduct tests on the differences in native and non-native discrimination tasks.\nThis research paper used a speech sound generator to create a series of sounds\nbetween two phones in order to see where and how categorical perception would\noccur. The parallel-resonance synthesizer generated 15 3-formant sounds that\nwould be used in the tests. The third formant (F3) was varied in frequency in\nsteps between the /ra/ and /la/ sounds. From this set of 15 sounds, there would\nbe two types of tests conducted on each subject group, an identification test\nand an oddity discrimination test. The subjects of this research consisted of 39\nnative American speakers and 21 native Japanese speakers. The discrimination\ntask was to listen to a series of three sounds, and make note of which of the\nthree was different. The results showed that the Americans could easily\ndiscriminate the target sound, only getting low scores if the sounds were\nambiguous as to if it was /r/ or /l/, "])</script><script>self.__next_f.push([1,"13:T41e,"])</script><script>self.__next_f.push([1,"In a study of brain plasticity and non-native lexical and segmentation\nprocesses, Sanders et al. in 2002 came up with interesting methods for probing\nnon-native speakers to see if learning the L2 early in life or later in life\nwould effect the ability to learn non-native lexical and segmentation processes.\nThis study would research various language subsystems such as lexico-semantic,\nsyntactic, and prosodic information processing. Using the earlier proposed\ntheories that each language uses different methods of speech segmentation\n(English: Stress-based, French: Syllable-based, Japanese: Mora-based) they tried\nto find if non-native speakers used lexico-syntactic information processes when\nsegmenting a non-native language (Sanders et al., 2002). Four groups were\nobtained to study this hypothesis, a group of native English speakers as a\ncontrol group (E), early English Japanese native speakers (JE), early English\nSpanish native speakers (SE), late English Japanese native speakers (J), and a\ngroup of late English Spanish native speakers (S). "])</script><script>self.__next_f.push([1,"14:T427,"])</script><script>self.__next_f.push([1,"In studies such as Otake (1993), findings were made that support the idea that\nnon-native speakers segment a foreign language using their native segmentation\nprocesses. Future research could focus on bilinguals learning an L2 that has a\ntotally different segmentation process. An example would be how a Japanese\nlearning English or an American learning French begins to learn a new\nsegmentation style, and how specific training on segmentation may make learning\nmore efficient. A similar study design that could be used would be Strange \u0026\nDittmanns’ (1984) study on the /r/ - /l/ distinction of Japanese speaking\nEnglish. This study could be applied to learning a new segmentation style. The\ntime of acquisition of a new non-native speech segmentation process would also\nbe of interest to this field. Also of interest to future research is the topics\nof multiple segmentation cues, such as lexico-semantic, and prosody, and how\nthese can be used interchangeably along with more native segmentation processes\nsuch as mora, syllable, or stress-based segmentation."])</script><script>self.__next_f.push([1,"6:[\"$\",\"article\",null,{\"className\":\"hentry h-entry\",\"children\":[[\"$\",\"header\",null,{\"children\":[[\"$\",\"h1\",null,{\"className\":\"entry-title p-name\",\"children\":\"Speech Segmentation in Japanese and English Bilinguals\"}],[\"$\",\"time\",null,{\"className\":\"display-date_published__A_L_d dt-published\",\"dateTime\":\"2003-12-14T00:00:00.000Z\",\"children\":\"Sunday December 14, 2003\"}],[\"$\",\"br\",null,{}],[\"$\",\"span\",null,{\"className\":\"h-card page_byline___vuXv\",\"children\":[\"by:\",\" \",[\"$\",\"span\",null,{\"className\":\"page_author__cAd1d fn p-author p-name\",\"children\":\"0xADADA\"}]]}]]}],[\"$\",\"div\",null,{\"className\":\"entry-content e-content\",\"children\":[[\"$\",\"p\",null,{\"children\":\"Colleges of Computer Sciences and Science (Psychology)\"}],\"\\n\",[\"$\",\"br\",null,{}],\"\\n\",[\"$\",\"p\",null,{\"children\":\"Northeastern University Boston, MA\"}],\"\\n\",[\"$\",\"br\",null,{}],\"\\n\",[\"$\",\"p\",null,{\"children\":\"Topics Concerning Japanese and English Bilinguals\"}],\"\\n\",[\"$\",\"h3\",null,{\"children\":\"A Literature Review\"}],\"\\n\",[\"$\",\"hr\",null,{}],\"\\n\",[\"$\",\"p\",null,{\"children\":\"The purpose of this paper is to provide an overview of the existing literature concerning speech segmentation, categorical perception, and some other issues concerning bilinguals of English and Japanese. It will touch on some of the differences in the two languages and how they affect learning the L2. The paper will start by providing background information about some of the two languages and some of the current issues involved in speech processing. The paper will then delve into the most current research, what the issues are, how it was done, and the results they have found. It will then go on to discuss the possible future directions of this research and end with references.\"}],\"\\n\",[\"$\",\"hr\",null,{}],\"\\n\",[\"$\",\"h2\",null,{\"children\":\"I. Introduction\"}],\"\\n\",[\"$\",\"p\",null,{\"children\":\"People trying to learn a second language always have a difficult task ahead of\\nthem. Learning a new grammar and lexicon takes both time and practice. Some\\nlanguages are diverse enough that on top of a new lexicon and grammar, there is\\nalso an entirely new segmentation system to be learned. Japanese and English are\\ndiverse in the way the speech streams are segmented into parts, with Japanese\\nusing the mora as the basic unit of perception (McQueen, Otake \u0026 Cutler, 2001)\\nand English using stress (Cutler \u0026 Butterfield, 1992). Along with learning a new\\nlexicon, grammar, and segmentation system is the problems with categorical\\nperception. How can bilinguals learn new sounds that aren’t in their native\\nlanguage? Another important issue is if there are multiple segmentation cues,\\ncan there be universal segmentation cues besides the rhythm-based mora, syllable\\nand stress-based processes? This paper will try to uncover these questions.\"}],\"\\n\",[\"$\",\"h3\",null,{\"children\":\"Background\"}],\"\\n\",[\"$\",\"p\",null,{\"children\":[\"When participating in conversation the listener must do a myriad of tasks to\\ncomprehend what the other speaker is saying. On the physical side of things, the\\ncomprehended must process the sound waves from the air into electrical signals\\ninto the brain. From there he/she must then begin the process of turning sound\\nsignals into words, phrases, sentences, and finally into a complete dialog. The\\naspect of changing the raw speech stream into words is called speech\\nsegmentation (Cutler, Hehler, Norris \u0026 Segui, 1986). Speech segmentation is\\nusually accomplished in different ways according to the language, the major\\nrhythm-based segmentation types are mora in Japanese, syllable in French\\n(Cutler, Hehler, Norris \u0026 Segui, 1986), and stress in English. The mora is the\\nsmallest Japanese unit of perception, it is subsyllabic. \",[\"$\",\"em\",null,{\"children\":\"“It can be a vocalic\\nnucleus, a nucleus plus syllable onset, or, as in the second and fourth morae of\\nshinshinto, it can be the postvocalic portion of a syllable, i.e., the coda.”\"}],\"$11\"]}],\"\\n\",[\"$\",\"h2\",null,{\"children\":\"II. Review of the existing literature\"}],\"\\n\",[\"$\",\"h3\",null,{\"children\":\"1. Discrimination of /r/ and /l/ by native speakers of Japanese and English\"}],\"\\n\",[\"$\",\"p\",null,{\"children\":[\"Categorical perception of speech sounds is an important aspect of speech\\nsegmentation. Without the ability to properly hear differences in non-native\\nspeech sounds, then segmentation and comprehension will be negatively impaired.\\nOne of the seminal research papers written comparing the abilities of English\\nand Japanese natives to discriminate the /r/ and /l/ sound was by Miyawaki,\\nStrange, Verbrugge, Liberman, Jenkins and Fujimura in 1975. The research here\\nconfirms earlier findings that Japanese subjects cannot distinguish between /r/\\nand /l/ (Goto, 1971). This paper investigated the effects of linguistic use on\\nthe ability to discriminate the class of liquid phones in English and Japanese\\nnatives. They focused on the phonemes /l/ and /r/ in syllable-initial position.\\nThe choice for the liquid /l/ and /r/ phones were made due to the fact that\\n\",[\"$\",\"em\",null,{\"children\":\"“the distinction between these phones is phonemic in English but not in\\nJapnanese.”\"}],\"$12\",[\"$\",\"em\",null,{\"children\":\"“pairs whose members were labeled as the\\nsame phoneme was considerable less accurate, although still above the 33% chance\\nlevel”\"}],\" (Miyawaki, et al. 1975). The Japanese however, showed a near-chance\\nlevel of discrimination. An interesting aspect of this study was the finding\\nthat when speech sound context was not included, the two groups behaved almost\\nidentically, \",[\"$\",\"em\",null,{\"children\":\"“we see very clearly that the Japanese do not differ from the\\nAmericans on any of the comparison pairs. The nonspeech discrimination functions\\nare virtually identical for the two groups of subjects.”\"}],\" (Miyawaki, et at.,\\n1975). Both groups were able to discriminate isolated F3 patterns quite\\naccurately, which indicates that both groups are able to hear sound differences\\nphysical sub-contextual level.\"]}],\"\\n\",[\"$\",\"p\",null,{\"children\":[\"A later study on the /r/ and /l/ perception task using a synthetic speech\\ngeneration process similar to the above study focused on if linguistic\\nexperience had an impact on categorical perception of the /r/ and /l/ phonemes.\\nThey were suggesting that \",[\"$\",\"em\",null,{\"children\":\"“... native Japanese adults learning English as a\\nsecond language are capable of categorical perception of /r/ and l/l.”\"}],\"\\n(MacKain, et al., 1981). This study was similar to the above, but had a few\\ndifferences. The first was how they varied the acoustic values both temporally\\nand spectrally \",[\"$\",\"em\",null,{\"children\":\"“to optimize the Japanese subjects’ opportunity to show\\nperceptual differentiation of the /r/-/l/ contrast.”\"}],\" (MacKain, et al., 1981).\\nThe second was the inclusion of an AXB oddity discrimination task which is\\nthought to provide a better opportunity to let the subjects detect auditory\\ndifferences. The third was an identification task for both the American and\\nJapanese groups. The Americans, as expected, displayed a strong category\\nboundary with strong identification scores. The not-experienced Japanese\\nsubjects displayed poor categorization of the /r/ and /l/ with near chance\\nlevels in all stimuli types. The results in the non-experienced Japanese group\\nextended the Miyawaki results. The experienced group \",[\"$\",\"em\",null,{\"children\":\"“had intensive English\\nconversation training with native American-English speakers and as a group spent\\na larger percentage of the average day conversing in English than did the\\nnot-experienced Japanese.”\"}],\" (MacKain, et at., 1981). This group displayed\\nsimilar results to the Americans on both the identification tasks and the\\ndiscrimination tasks. These results suggests \",[\"$\",\"em\",null,{\"children\":\"“that the occurrence and\\nabruptness of an /r/-/l/ category boundary for the experience Japanese might be\\nrelated to their grater conversational English experience…”\"}],\" (MacKain et al.,\\n1981). This particular study had added the AXB oddity task because it is less\\nmemory demanding and \",[\"$\",\"em\",null,{\"children\":\"“they could use nonphoenetic auditory memory to aid\\nperformance”\"}],\" (MacKain et al., 1981) in the hopes that it would allow the\\nnon-experienced Japanese to obtain better results, but this particular task did\\nnot achieve the hopes of its design intentions. Overall, their research\\nsuggested that Japanese native speakers can obtain categorical perception of /r/\\nand /l/ with some practice and more experience, which is good news to aspiring\\nbilinguals.\"]}],\"\\n\",[\"$\",\"p\",null,{\"children\":[\"Research into the /r/ and /l/ phonemes is interesting particularly to Japanese\\nbecause of the lack of contrast between these sounds. Distinctive contrast in\\nparticular speech sounds allows speakers of that language to discriminate where\\nother language speakers would not. The above studies examined this aspect as\\nwell, but in a 1984 study by Strange and Dittmann focused on how the ability to\\ndiscriminate sounds not available in the L1 can change with explicit training,\\n\",[\"$\",\"em\",null,{\"children\":\"“We were interested in whether we could modify the perception of AE\\nword-initial /r/ and /l/ by adult Japanese learners of English, in the\\nlaboratory, using the psychophysical training task successfully employed by\\nCarney et al. (1977).”\"}],\" (Strange \u0026 Dittmann, 1984). The design of this study was\\nto test the abilities of eight female Japanese native speakers before training\\nand then again after training to examine the effects of training on\\ndiscrimination of the /r/ and /l/ series of synthetic speech sounds. The initial\\npre-training tests consisted of a minimal pairs test, an identification of the\\nrock-lock series and an oddity discrimination task. The training was done\\nindividually over a three week period that totaled 14 to 18 sessions, it\\nconsisted of an AX discrimination task with immediate feedback. At the end of\\nthe training the post-training tests were given, which were the same as the\\npre-training tests. Pre-training results were similar to the results found in by\\nMacKain in 1981, with near-chance levels of accuracy. The training task\\nperformance showed \",[\"$\",\"em\",null,{\"children\":\"“gradual improvement over session with the greatest\\nimprovement in the first several sessions”\"}],\" (Strange \u0026 Dittmann, 1984). All\\nsubjects showed increased performance as the training sessions progressed. After\\nthe training, the post-training tests showed that \",[\"$\",\"em\",null,{\"children\":\"“pretraining versus\\nposttraining categorical perception tests for each of the eight subjects of the\\nrock-lock series revealed that seven of the eight subjects improved as a\\nfunction of the training.”\"}],\" (Strange \u0026 Dittmann, 1984). Post-training test\\nresults also showed improvement in their discrimination of cross-category pairs\\nwith over 75% correct (Strange \u0026 Dittmann, 1984). Overall, training did indicate\\nimprovement as performance on post-training tests showed better performance\\nresults (Strange \u0026 Dittmann, 1984). \",[\"$\",\"em\",null,{\"children\":\"“We can thus conclude that training with a\\nfixed-standard AX discrimination task resulted in improved (categorical)\\nperception of the training stimuli, as tested by the (more demanding)\\nidentification and oddity discrimination tasks”\"}],\" (Strange \u0026 Dittmann, 1984).\\nThis study also tested differences in sound according to acoustic properties.\\nThey wanted to test if training in the /rock/ - /lock/ set would transfer over\\nto good performance in a similar /rake/ - /lake/ test. Their results showed that\\nit was indeed the case, and training did help this test achieve improved\\nperformance, this also supports the idea that bilinguals can indeed learn to\\nperceive new sounds in a second language.\"]}],\"\\n\",[\"$\",\"h3\",null,{\"children\":\"2. Speech segmentation using the Mora\"}],\"\\n\",[\"$\",\"p\",null,{\"children\":\"One of the major differences in a language is how it is timed, or the rhythm of\\nthe language. Bilinguals not only have to learn a new lexicon and grammar\\nsystem, but sometimes must also learn a new rhythm to speak their L2. An example\\nof this would be a native English speaker trying to learn Japanese or\\nvise-versa. English is a stress-timed language whereas Japanese is mora-timed.\\nResearch of the mora can help lead to further understanding of how languages of\\ndifferent timing style can be learned more efficiently for bilinguals as well as\\nhow differences in timing can affect different aspects of speech segmentation.\"}],\"\\n\",[\"$\",\"p\",null,{\"children\":[\"In a study by Otake et al., 1993, of how Japanese words are segmented by native\\nand non-native listeners, results found that Japanese responses were consistent\\nwith moraic segmentation, while non-native listeners responded differently. The\\nmora is a uniquely Japanese timing mechanism; it is smaller than a syllable, and\\nis considered the basic unit of perception. This study set up four experiments\\nwith native and non-native speakers to examine the effects of native timing type\\non Japanese words. In the first experiment 40 native Japanese speakers were used\\nto listen to a series of 3 to 6 words. When a word was heard with the target\\nletters on a printed card, the subject was to press a button. Results showed\\nthat the native Japanese listeners responses better supported the mora\\nhypothesis than the syllable hypotheses, confirming their initial hypothesis\\nthat Japanese speakers will segment words best with the mora-timed segmentation\\nstyle. \",[\"$\",\"em\",null,{\"children\":\"“The pattern of results in this experiment thus appears to offer strong\\nsupport for the mora hypothesis but none to the syllable hypothesis.”\"}],\" (Otake et\\nal, 1993). The second experiment tested English speaking subjects on Japanese\\nwords. The design was similar to the previous task on the Japanese subjects,\\nwhere a series of Japanese words would be played, and the subject was to press a\\nbutton once the sound on the printed card was heard. The results of this\\nexperiment are in stark contrast with that of experiment 1. The findings in this\\nexperiment support that \",[\"$\",\"em\",null,{\"children\":\"“we many now conclude that English listeners do not\\nexploit mora structure in the same way.”\"}],\" (Otake et al., 1993) [as Japanese\\nnative listeners]. A note about experiment 1, the targets were presented on\\nprinted card in Roman text orthography, this can introduce confounds due to how\\nJapanese naturally represent sounds with kana characters. Experiment 3 was\\nexactly the same design as experiment 1 with the exception that the target word\\nwas played through the headphones before the word sequence rather than being\\nprinted on a card. Experiment 3 had 40 native Japanese speaking subjects. The\\ntarget sound was played first, followed by the sequences of test words. The\\nsubject would press a button when they heard the target word in the sequence.\\nThe results of experiment 3 replicated those of experiment 1. \",[\"$\",\"em\",null,{\"children\":\"“The replication\\nof experiment 1’s results strongly confirms our conclusions from the preceding\\nexperiments: Japanese listeners do not naturally segment speech syllable by\\nsyllable; they do naturally segment it mora by mora.”\"}],\" (Otake et al., 1993).\\nThese findings also cleared up the problem of orthography of Japanese speech\\nsounds mentioned earlier. Experiment 4 was identical to experiment 3 with the\\nexception of the subjects being 33 native French speakers. The results of\\nexperiment 4 were as expected, \",[\"$\",\"em\",null,{\"children\":\"“the response patterns of French listeners are,\\nas predicted, best accounted for by the syllabic hypothesis…”\"}],\" (Otake et al.,\\n1993). These results also support findings by Cutler et al., 1986. Finally,\\nthese results support the predictions made initially, that non-native listeners\\nwill \",[\"$\",\"em\",null,{\"children\":\"“not replicate the pattern of results shown with the same materials by\\nnative Japanese listeners”\"}],\" (Otake et al., 1993). These results support that\\nnon-native listeners will try to segment the sounds of a non-native language by\\napplying their native speech segmentation system, whether its mora-based,\\nstress-based or syllable-based. How could that affect learning a second language\\nwhere the segmentation process is different from the native language?\"]}],\"\\n\",[\"$\",\"p\",null,{\"children\":[\"Taking from some of the findings from the previous study, Cutler and Otake\\nstarted a new research project in 1994 that would focus on whether subjects\\nwould apply their native segmentation processes to a foreign language. This\\nresearch could show that inappropriate use of a segmentation process could\\ninhibit the processing of a non-native language in bilinguals. \",[\"$\",\"em\",null,{\"children\":\"“This suggests\\nthat segmentation procedures may indeed be highly similar to phonological\\ncategorization procedures: they effectively aid processing of the native\\nlanguage, but they may reduce processing efficiency for input in a foreign\\nlanguage.”\"}],\" (Cutler \u0026 Otake, 1994). This study also hoped to further support the\\nmora hypothesis put forth by Otake in 1993. The first experiment was to test\\nJapanese native speakers on if moraic targets \",[\"$\",\"em\",null,{\"children\":\"“will be easier to detect than\\nnonmoraic”\"}],\" (Cutler \u0026 Otake, 1994). This should prove to be the case under the\\nmora hypothesis. This experiment will also test for whether phoneme detection\\n\",[\"$\",\"em\",null,{\"children\":\"“will be differentially difficult for vowels versus consonants”\"}],\" (Cutler \u0026\\nOtake, 1994). Experiment 1 was designed with 40 native Japanese speakers, they\\nwould listen for a target sound (O or N) in a series of Japanese words, and\\npress a response key as soon as they detected the sound. The results from this\\nexperiment showed the same results seen in Otake (1993): \",[\"$\",\"em\",null,{\"children\":\"“mora structure is\\ncrucially involved in the process by which Japanese listeners convert spoken\\ninput in lexically accessible representation.”\"}],\" (Cutler \u0026 Otake, 1993), as well\\nas showing that quick responses to moraic input is not only restricted to CV\\ninput as seen in Otakes’ 1993 experiment. It should be noted that there were no\\nsignificant findings concerning the differences in vowel and consonant response\\ntimes mentioned earlier. Experiment 2 was conducted in the same way as\\nexperiment 1, with the exception that the subjects were 24 English native\\nspeakers. As expected, the non-native speakers did not demonstrate the moraic\\neffects shown in experiment 1. Interestingly, \",[\"$\",\"em\",null,{\"children\":\"“The main effect of vowel versus\\nconsonant target was, however, significant; consonants were detected both faster\\nand more accurately than vowels”\"}],\" (Cutler \u0026 Otake, 1994). This supports the\\nearlier findings that native listeners apply their native segmentation\\nprocedures to a non-native language. Experiment 3 was similar to experiment 2\\nexcept with English words as both target and sequence words. The subjects were\\n24 native English speakers. Findings in experiment 3 showed that \",[\"$\",\"em\",null,{\"children\":\"“These\\nfindings are in line with previous failures to find significant phoneme\\ndetection differences between targets in stressed versus unstressed position\\nwith English listeners and laboratory-read speech.”\"}],\" (Cutler \u0026 Otake, 1994).\\nThese results were similar to experiment 2. Experiment 4 used the same materials\\nas experiment 3, English words, while it used the same design, as well as the\\nsame subjects as in experiment 1, using Japanese native speakers. Results in\\nthis experiment found the vowel sounds were much more difficult to find than the\\nconsonantal targets (Cutler \u0026 Otake, 1994). The findings of experiment 4 also\\nhelp support the mora hypothesis, namely \",[\"$\",\"em\",null,{\"children\":\"“that mismatch between in the input\\nand the native language phonemic repertoire plays a role in phoneme detection in\\na foreign language.”\"}],\" (Cutler \u0026 Otake, 1994). Experiment 5 was designed with 20\\nnative Japanese speakers listening to a played back words of native Japanese.\\nThe procedure was that of experiment 1. The subjects were to press a button when\\nthey heard a target phoneme in the played back word sequence. The results of\\nthis experiment demonstrated what the experimenters had hoped for, \",[\"$\",\"em\",null,{\"children\":\"“a new\\neffect in Japanese phoneme-monitoring: targets in word-initial position are\\ndetected faster than targets in word-medial position.”\"}],\" (Cutler \u0026 Otake, 1994).\\nThis experiment showed the mora effect was significant for all four phoneme\\ntargets. Experiment 6 involved doing the same as experiment 5 but with English\\nsubjects. This experiment was designed to show the English speakers advantage of\\ndetection of vowels over consonant targets, as well as observing a difference in\\nRTs in A and O due to \",[\"$\",\"em\",null,{\"children\":\"“phoneme repertoire mismatch”\"}],\" (Cutler \u0026 Otake, 1994).\\nThis experiment used the same materials in experiment 5 with 23 native English\\nspeakers using the procedures from experiment 2. The results of this experiment\\nshowed that \",[\"$\",\"em\",null,{\"children\":\"“there was again a significant overall advantage for consonant over\\nvowel targets”\"}],\" (Cutler \u0026 Otake, 1994). Overall these experiments had shown that\\nthe \",[\"$\",\"em\",null,{\"children\":\"“the moraic effect which Japanese listeners show in phoneme detection in\\ntheir native language appears in world-initial well as in word-medial position\\nand with a variety of phoneme targets.”\"}],\" (Cutler \u0026 Otake, 1994). These\\nexperiments also go to explain that the consonant and vowel detection abilities\\nof English speakers appear when listening to Japanese, due to native English\\nsegmentation process advantages in this particular task.\"]}],\"\\n\",[\"$\",\"p\",null,{\"children\":[\"In terms of bilinguals, the above studies used Japanese native speakers, some of\\nwhom had some English experience. Even with experience, it was shown that they\\nwere still applying mora segmentation to English input, as well as English\\nspeakers applying stress-based segmentation when it is inappropriate in Japanese\\ninput. As quoted from the above study \",[\"$\",\"em\",null,{\"children\":\"“We believe that this finding has\\npotentially important implication for understanding the processes of acquisition\\nof a second language.”\"}],\" (Cutler \u0026 Otake, 1994). Although this research seems to\\ncast a dim picture on those trying to learn a second language, all is not lost,\\nin a study by Cutler et al., 1992, showed that more than one segmentation\\nprocess is available, and even if not available, these rhythm based processes\\nare heuristics for processing a non-native language, are not necessary for\\ncomprehension. (Cutler et al., 1992).\"]}],\"\\n\",[\"$\",\"h3\",null,{\"children\":\"3. Rhythmic cues and the Lexicon\"}],\"\\n\",[\"$\",\"p\",null,{\"children\":[\"An important area of study is on how rhythmic cues in the speech stream affect\\nlexical decisions in Japanese. A learner of Japanese would be affected by this\\nin that many languages don’t use rhythmic cues, and so in learning Japanese,\\nrhythmic cues may not serve as an available heuristic. Japanese provides a good\\ntest platform to study rhythmic cues and speech segmentation because Japanese\\n\",[\"$\",\"em\",null,{\"children\":\"“rhythm is based neither on syllables nor on stress. Instead, it is based on\\nthe mora, a subsyllabic unit which can be of five different types”\"}],\" (McQueen et\\nal, 2001).\"]}],\"\\n\",[\"$\",\"p\",null,{\"children\":[\"In a study by Cutler and Otake, examining old Japanese wood-block prints which\\ncontained a word-based joke system called “Goroawase” to examine if there\\nexisted sub-moraic information processing in the speech stream. This joke system\\nis used by substituting a single mora in a word with another mora to create a\\nsimilar sounding word with a different meaning, thus creating a word-pun. Their\\nfindings suggest that \",[\"$\",\"em\",null,{\"children\":\"“mora substitution is more often than would be expected\\nby chance in effect phoneme substitution because two words which overlap in all\\nbut a single consonant or vowel form a better target-pun pair than two words\\nwhich overlap in all but a CV mora.”\"}],\" (Cutler \u0026 Otake, 2002). Another experiment\\nin the same paper uses word reconstruction. They had subjects listen to a word\\nwith a replaced mora, and were told which mora was changed. The subjects were\\nthen to tell which word had been intended. This experiment would use mora as the\\ncue to the target word, which would then be accessed via the lexicon. 45 native\\nJapanese speaking subjects partook in this experiment and the results were as\\nexpected. 4 mora words were more easily accessed than 3 mora words. Their\\nresults suggested that \",[\"$\",\"em\",null,{\"children\":\"“word reconstruction was significantly easier when the\\ninitial mora had been replaced by another mora sharing with it either C or V.”\"}],\"\\n(Cutler \u0026 Otake, 2002). In their second experiment, they distorted the final\\nmora of the word, and found that identification was faster and more accurate,\\nwhich suggests \",[\"$\",\"em\",null,{\"children\":\"“that this information can be exploited continuously rather than\\nonly on a mora-by-mora basis”\"}],\" (Cutler \u0026 Otake, 2002). This indicates that\\nlexical access can occur without complete moraic information. In experiments 3\\nand 4 of their research, they tested replacing both third and fourth mora and\\nplaced a focus on consonant versus vowel replacement, they found similar results\\nto experiment two. \",[\"$\",\"em\",null,{\"children\":\"“Although both the V-replacement and C-replacement condition\\nproved easier than M-replacements, there was also a difference between the first\\ntwo: Replacement of a vowel proved easier than replacement of a consonant.”\"}],\"\\n(Cutler \u0026 Otake, 2002). On their 5th experiment, they used a Yes/No type\\nresponse to the design of the previous experiment, their results helped to\\ncement their conclusion that there is continuous speech processing, even below\\nthe level of the mora. (Cutler \u0026 Otake, 2002). This does not suggest that there\\nis no mora, but only that continuous speech sounds are helpful to the\\nsegmentation of the continuous speech stream (Cutler \u0026 Otake, 2002). Their\\nresults do however suggest, and support the findings of Norris et al., in 1997,\\n\",[\"$\",\"em\",null,{\"children\":\"“that the contribution of rhythmic categories in word recognition is the same\\nfor all languages”\"}],\" (Cutler \u0026 Otake, 2002). As rhythmic categories are universal\\nto all languages (Norris et al., 1997), this would provide some relief to\\nlearners of Japanese a second language, as mora are not the end-all to\\nsegmentation, but a heuristic function that helps to make segmentation more\\nefficient.\"]}],\"\\n\",[\"$\",\"p\",null,{\"children\":[\"If mora and meter are both parts of speech segmentation, how can we combine the\\ntwo? A study by McQueen, Otake and Cutler in 2001 tries to answer that. Their\\nexperiments use the PWC, or Possible Word Constraint developed by Norris et al.,\\nin 1997 to test if Japanese speakers use the PWC just as English and Dutch\\nspeakers. The PWC is another type of heuristic function used in speech\\nsegmentation particular to the Shortlist model developed by Norris et al.,\\n(1997). Their first experiment used 54 native Japanese speakers to listen to a\\nnative speaker of Japanese pronounce nonwords with Japanese words embedded\\nwithin them. The subjects were then to press a button and pronounce the embedded\\nword once they heard it. The results of the experiment showed that indeed,\\n\",[\"$\",\"em\",null,{\"children\":\"“listeners find it harder to spot words in impossible word contexts than in\\npossible word contexts. Japanese listeners therefore appear to use the PWC when\\nsegmenting speech.”\"}],\" (McQueen, Otake \u0026 Cutler, 2001). Other tests done in this\\nstudy all supported the PWC and show similar results done with English speakers.\\n(McQueen, Otake \u0026 Cutler, 2001). The PWC suggests the speech segmentation is\\nmore universal than previously devised models. This model suggests that words\\nare activated and no particular lexical decision is 100% decided, until all are\\ndecided. \",[\"$\",\"em\",null,{\"children\":\"“The present experiments therefore support the theory of lexical\\nsegmentation that the PWC offers. On this view, candidate words are activated by\\nthe incoming speech stream and compete with each other until a lexical parse is\\nsettled upon.”\"}],\" (McQueen, Otake \u0026 Cutler, 2001). This model also allows for the\\nrhythmic segmentation process to exist and help add to the parsing of lexical\\nand segmental structure. \",[\"$\",\"em\",null,{\"children\":\"“Furthermore, just as the rhythmic structure of\\nEnglish or Dutch provides English and Dutch listeners with cues to the location\\nof likely word boundaries (Cutler \u0026 Norris, 1988, Vroomen et at., 1996), so too\\ndoes the characteristic rhythm of Japanese provide Japanese listeners with a\\nsegmentation cue.”\"}],\" (McQueen, Otake \u0026 Cutler, 2001).\"]}],\"\\n\",[\"$\",\"p\",null,{\"children\":\"Rhythmic segmentation provides another type of segmentation heuristic along with\\nmora-based segmentation as seen in the above papers. Although bilinguals have\\ntrouble when inappropriately applying their native language segmentation style\\nto a non-native language, rhythmic segmentation is a universal heuristic which\\nexists to compensate when L1 segmentation style fails to properly segment the\\nnon-native language.\"}],\"\\n\",[\"$\",\"h3\",null,{\"children\":\"4. Segmentation in non-native languages\"}],\"\\n\",[\"$\",\"p\",null,{\"children\":\"An important area of study concerning bilingual speech segmentation is how\\nnon-native speakers segment their second language (L2). If non-native speakers\\ncan use any of the non-native language rhythmic, prosodic, lexico-syntatic, and\\nsyntactic segmentation processes, then they will have a much easier time\\nsegmenting the L2. The ability to learn a non-native segmentation process would\\nbe beneficial to any bilingual as it would facilitate comprehension of the L2.\\nResearch into brain plasticity for learning non-native language processes would\\ndirectly benefit the existing body of knowledge.\"}],\"\\n\",[\"$\",\"p\",null,{\"children\":[\"$13\",[\"$\",\"em\",null,{\"children\":\"“If non-native speakers fail\\nto use rhythmic segmentation cues other than the rhythmic cues relevant to their\\nL1, native speakers of Japanese (mora-timed) and Spanish (syllable-timed) would\\nnot be expected to use stress pattern as a segmentation cue when listening to\\nEnglish. Alternatively, native Japanese and native Spanish speakers might differ\\nin their abilities to use stress pattern as a segmentation cue in English.”\"}],\"\\n(Sanders et al., 2002). For this experiment they created 5 groups of 3 sentences\\neach. The 5 groups were \",[\"$\",\"em\",null,{\"children\":\"“Strong stress, initial position (SI), strong stress,\\nmedial position (SM), weak stress, initial position (WI), weak stress, medial\\nposition (WM), and target absent (TA).”\"}],\" (Sanders et al., 2002). Each group\\ncontained 3 sentences each of which were a semantic, syntactic or acoustic\\ntarget sentence. The semantic words were normal English sentences, the syntactic\\nsentences replaced all open-class words with non-words, and the acoustic words\\nonly retained the original prosody. Participants were asked to listen to a\\ntarget, and then were asked to press one button if that target was heard in the\\nbeginning of the sentence, another button if it was heard in the middle, and the\\nthird button if it was not heard. Results indicated that \",[\"$\",\"em\",null,{\"children\":\"“the fact that both\\ngroups of late-learners were able to use the lexical information supports the\\nhypothesis that the lexico-semantic system remains relatively plastic beyond the\\nage of 12.”\"}],\" (Sanders et al., 2002). These results support the idea that late\\nlearners can learn non-native language processes later in life, which is a\\nreassuring fact for late-bilinguals, however \",[\"$\",\"em\",null,{\"children\":\"“No group of non-native speakers\\nused syntactic information to the same extent as native speakers.”\"}],\" (Sanders et\\nal., 2002). These results, as well as other indicate that syntactic information\\nprocesses are not as easily learned later in life (Sanders et al., 2002). An\\ninteresting finding was how both early and late learners of English\\nJapanese-natives were able to use some segmentation cues that are seemingly\\neffective in both English and Japanese; \",[\"$\",\"em\",null,{\"children\":\"“this study could either indicate that\\nboth groups were applying a Japanese segmentation cue that happens to co-occur\\nwith stress in English or that both groups had enough exposure to English to\\nlearn a new segmentation cue.”\"}],\" (Sanders et al., 2002). Overall the findings of\\nthis study show that both lexical and semantic segmentation subsystems retain\\nthe \",[\"$\",\"em\",null,{\"children\":\"“ability to change to a greater degree than do syntactic subsystems”\"}],\"\\n(Sanders et al., 2002).\"]}],\"\\n\",[\"$\",\"p\",null,{\"children\":[\"In terms of bilinguals, some very reassuring findings from the above study is\\nthat some segmentation processes are still learnable later in life, and they are\\nalso interchangeable, one or more can be used when another is unavailable or not\\napplicable. \",[\"$\",\"em\",null,{\"children\":\"“The findings also indicate that segmentation cues can be used\\nflexibly by both native and non-native speakers, such that cues that are both\\navailable in the speech stream and usable by the listener are employed to a\\ngreater extent when other segmentation cues are either absent or not accessible\\nto the listener.”\"}],\" (Sanders et al., 2002).\"]}],\"\\n\",[\"$\",\"h2\",null,{\"children\":\"III. Possible directions for future research\"}],\"\\n\",[\"$\",\"p\",null,{\"children\":\"$14\"}],\"\\n\",[\"$\",\"h2\",null,{\"children\":\"References\"}],\"\\n\",[\"$\",\"cite\",null,{\"class\":\"hanging-indent\",\"children\":[\"$\",\"p\",null,{\"children\":[\"Beckman, M. (1982). Segment Duration and the ‘Mora’ in Japanese. \",[\"$\",\"em\",null,{\"children\":\"Phonetica\"}],\",\\n39, 113-135.\"]}]}],\"\\n\",[\"$\",\"cite\",null,{\"class\":\"hanging-indent\",\"children\":[\"$\",\"p\",null,{\"children\":[\"Cutler, A., \u0026 Butterfield, S. (1992). Rhythmic cues to speech segmentation:\\nEvidence from juncture misperception. \",[\"$\",\"em\",null,{\"children\":\"Journal of Memory and Langauge\"}],\", 31,\\n218-236.\"]}]}],\"\\n\",[\"$\",\"cite\",null,{\"class\":\"hanging-indent\",\"children\":[\"$\",\"p\",null,{\"children\":[\"Cutler, A., Mehler, J., Norris, D., Segui, J., (1986). The Syllable’s Differing\\nRole in the Segmentation of French and English. \",[\"$\",\"em\",null,{\"children\":\"Journal of Memory and\\nLanguage\"}],\", 25, 385-400.\"]}]}],\"\\n\",[\"$\",\"cite\",null,{\"class\":\"hanging-indent\",\"children\":[\"$\",\"p\",null,{\"children\":[\"Cutler, A., \u0026 Norris, D. (1988). The role of strong syllables in segmentation\\nfor lexical access. \",[\"$\",\"em\",null,{\"children\":\"Journal of Experimental Psychology: Human Perception and\\nPerformance\"}],\", 14, 113-121.\"]}]}],\"\\n\",[\"$\",\"cite\",null,{\"class\":\"hanging-indent\",\"children\":[\"$\",\"p\",null,{\"children\":[\"Cutler, A., Otake, T. (2002). Rhythmic Categories in Spoken-Word Recognition.\\n\",[\"$\",\"em\",null,{\"children\":\"Journal of Memory and Language\"}],\", 46, 296-322.\"]}]}],\"\\n\",[\"$\",\"cite\",null,{\"class\":\"hanging-indent\",\"children\":[\"$\",\"p\",null,{\"children\":[\"Cutler, A., Otake, T. (1994). Mora or Phoneme? Further Evidence for\\nLangauge-Specific Listening. \",[\"$\",\"em\",null,{\"children\":\"Journal of Memory and Language\"}],\", 33, 824-844.\"]}]}],\"\\n\",[\"$\",\"cite\",null,{\"class\":\"hanging-indent\",\"children\":[\"$\",\"p\",null,{\"children\":[\"Goto, H. (1971). Auditory perception by normal Japanese adults of the sounds “L”\\nand “R”. \",[\"$\",\"em\",null,{\"children\":\"Neuropsychologia\"}],\", 9, 317-323.\"]}]}],\"\\n\",[\"$\",\"cite\",null,{\"class\":\"hanging-indent\",\"children\":[\"$\",\"p\",null,{\"children\":[\"MacKain, K. S., Best, C. T., Strange, W. (1981). Categorical perception of\\nEnglish /r/ and /l/ by Japanese bilinguals. \",[\"$\",\"em\",null,{\"children\":\"Applied Psycholinguistics\"}],\", 2,\\n369-390.\"]}]}],\"\\n\",[\"$\",\"cite\",null,{\"class\":\"hanging-indent\",\"children\":[\"$\",\"p\",null,{\"children\":[\"McQueen, M. J., Otake, T., Cutler, A., (2001). Rhythmic Cues and Possible-Word\\nConstraints in Japanese Speech Segmentation. \",[\"$\",\"em\",null,{\"children\":\"Journal of Memory and Language\"}],\",\\n45, 103-132.\"]}]}],\"\\n\",[\"$\",\"cite\",null,{\"class\":\"hanging-indent\",\"children\":[\"$\",\"p\",null,{\"children\":[\"Miyawaki, K., Strange, W., Verbrugge, R., Liberman, A. M., Jenkins, J. J.,\\nFujimura, O. (1975). An effect of linguistic experience: The discrimination of\\n[r] and [l] by native speakers of Japanese and English, \",[\"$\",\"em\",null,{\"children\":\"Perception \u0026\\nPsychophysics\"}],\", 18, 331-340.\"]}]}],\"\\n\",[\"$\",\"cite\",null,{\"class\":\"hanging-indent\",\"children\":[\"$\",\"p\",null,{\"children\":[\"Norris, D. G., McQueen, J. M., Cutler, A., \u0026 Butterfield, S. (1997). The\\npossible-word constraint in the segmentation of continuous speech. \",[\"$\",\"em\",null,{\"children\":\"Cognitive\\nPsychology\"}],\", 34 191-243\"]}]}],\"\\n\",[\"$\",\"cite\",null,{\"class\":\"hanging-indent\",\"children\":[\"$\",\"p\",null,{\"children\":[\"Otake, T., Hatano, G., Cutler, A., Mehler, J., (1993) Mora or Syllable? Speech\\nSegmentation in Japanese. \",[\"$\",\"em\",null,{\"children\":\"Journal of Memory and Language\"}],\", 32, 258-278.\"]}]}],\"\\n\",[\"$\",\"cite\",null,{\"class\":\"hanging-indent\",\"children\":[\"$\",\"p\",null,{\"children\":[\"Sanders, L. D., Neville, H. J., Woldorff, M. G., (2002). Speech Segmentation by\\nNative and Non-Native Speakers: The Use of Lexical, Syntactic, and\\nStress-Pattern Cues. \",[\"$\",\"em\",null,{\"children\":\"Journal of Speech, Language, and Hearing Research\"}],\", 45,\\n519-530.\"]}]}],\"\\n\",[\"$\",\"cite\",null,{\"class\":\"hanging-indent\",\"children\":[\"$\",\"p\",null,{\"children\":[\"Strange, W., Dittmann, S., (1984).\\nEffects of discrimination training on the\\nperception of /r-l/ by Japanese adults learning English.\\n\",[\"$\",\"em\",null,{\"children\":\"Perception \u0026 Psychophysics\"}],\",\\n36(2), 131-145.\"]}]}]]}],[\"$\",\"footer\",null,{\"className\":\"license_copyright__EpMnZ\",\"children\":[\"This is licensed under a Creative Commons \",\"cc-by-nc-sa\",\" International License\"]}]]}]\n"])</script><script>self.__next_f.push([1,"e:[[\"$\",\"meta\",\"0\",{\"name\":\"viewport\",\"content\":\"width=device-width, initial-scale=1\"}],[\"$\",\"meta\",\"1\",{\"charSet\":\"utf-8\"}],[\"$\",\"title\",\"2\",{\"children\":\"Speech Segmentation in Japanese and English Bilinguals\"}],[\"$\",\"meta\",\"3\",{\"name\":\"description\",\"content\":\"The purpose of this paper is to provide an overview of the existing literature concerning speech segmentation, categorical perception, and some other issues concerning bilinguals of English and Japanese\"}],[\"$\",\"link\",\"4\",{\"rel\":\"author\",\"href\":\"https://0xadada.pub\"}],[\"$\",\"meta\",\"5\",{\"name\":\"author\",\"content\":\"0xADADA\"}],[\"$\",\"meta\",\"6\",{\"name\":\"keywords\",\"content\":\"essays,Japanese\"}],[\"$\",\"link\",\"7\",{\"rel\":\"alternate\",\"type\":\"application/rss+xml\",\"href\":\"https://0xadada.pub/rss.xml\"}],[\"$\",\"meta\",\"8\",{\"property\":\"og:title\",\"content\":\"Speech Segmentation in Japanese and English Bilinguals\"}],[\"$\",\"meta\",\"9\",{\"property\":\"og:description\",\"content\":\"The purpose of this paper is to provide an overview of the existing literature concerning speech segmentation, categorical perception, and some other issues concerning bilinguals of English and Japanese\"}],[\"$\",\"meta\",\"10\",{\"property\":\"og:url\",\"content\":\"https://0xadada.pub/2003/12/14/speech-segmentation-in-japanese-and-english-bilinguals/\"}],[\"$\",\"meta\",\"11\",{\"property\":\"og:site_name\",\"content\":\"0xADADA\"}],[\"$\",\"meta\",\"12\",{\"property\":\"og:locale\",\"content\":\"en_US\"}],[\"$\",\"meta\",\"13\",{\"property\":\"og:image\",\"content\":\"https://0xadada.pub/static/images/meta/avatar.svg\"}],[\"$\",\"meta\",\"14\",{\"property\":\"og:image:width\",\"content\":\"660\"}],[\"$\",\"meta\",\"15\",{\"property\":\"og:image:height\",\"content\":\"660\"}],[\"$\",\"meta\",\"16\",{\"property\":\"og:type\",\"content\":\"article\"}],[\"$\",\"meta\",\"17\",{\"name\":\"twitter:card\",\"content\":\"summary_large_image\"}],[\"$\",\"meta\",\"18\",{\"name\":\"twitter:title\",\"content\":\"Speech Segmentation in Japanese and English Bilinguals\"}],[\"$\",\"meta\",\"19\",{\"name\":\"twitter:description\",\"content\":\"The purpose of this paper is to provide an overview of the existing literature concerning speech segmentation, categorical perception, and some other issues concerning bilinguals of English and Japanese\"}],[\"$\",\"meta\",\"20\",{\"name\":\"twitter:image\",\"content\":\"https://0xadada.pub/static/images/meta/avatar.svg\"}],[\"$\",\"meta\",\"21\",{\"name\":\"twitter:image:width\",\"content\":\"660\"}],[\"$\",\"meta\",\"22\",{\"name\":\"twitter:image:height\",\"content\":\"660\"}],[\"$\",\"link\",\"23\",{\"rel\":\"icon\",\"href\":\"/favicon.ico\",\"type\":\"image/x-icon\",\"sizes\":\"48x48\"}],[\"$\",\"link\",\"24\",{\"rel\":\"apple-touch-icon\",\"href\":\"/apple-icon.png?b764b3a1dbf00a82\",\"type\":\"image/png\",\"sizes\":\"180x180\"}]]\n"])</script><script>self.__next_f.push([1,"5:null\n"])</script><script>self.__next_f.push([1,""])</script></body></html>