<!DOCTYPE html><html><head><meta charSet="utf-8"/><title>on logging</title><meta property="og:site_name" content="0xADADA"/><meta property="og:title" content="on logging"/><meta name="twitter:title" content="on logging"/><link rel="canonical" href="https://0xadada.pub/2015/11/05/on-logging/"/><meta property="og:url" content="https://0xadada.pub/2015/11/05/on-logging/"/><meta name="twitter:url" content="https://0xadada.pub/2015/11/05/on-logging/"/><meta name="twitter:card" content="summary"/><meta name="twitter:site" content="@0xadada"/><meta name="author" content="0xADADA"/><meta property="og:type" content="article"/><meta name="description" content="Thoughts and best practices on application logging"/><meta name="twitter:description" content="Thoughts and best practices on application logging"/><meta name="viewport" content="width=device-width, initial-scale=1"/><link rel="icon" href="https://0xadada.pub/favicon.ico"/><link rel="home" href="https://0xadada.pub/"/><link rel="manifest" href="https://0xadada.pub/static/images/meta/0xadada.webmanifest"/><link rel="apple-touch-icon" href="https://0xadada.pub/static/images/meta/apple-touch-icon.png"/><link rel="icon" type="image/png" href="https://0xadada.pub/static/images/meta/favicon-32x32.png" sizes="32x32"/><link rel="icon" type="image/png" href="https://0xadada.pub/static/images/meta/favicon-16x16.png" sizes="16x16"/><link rel="mask-icon" href="https://0xadada.pub/static/images/meta/safari-pinned-tab.svg" color="#5bbad5"/><meta name="msapplication-config" content="https://0xadada.pub/static/images/meta/browserconfig.xml"/><meta name="theme-color" content="#FDF9F0"/><meta name="pocket-site-verification" content="7431f135e23a84de547e5b79dab406"/><meta name="next-head-count" content="25"/><link rel="preload" href="/_next/static/css/64aa077ca96507d3.css" as="style"/><link rel="stylesheet" href="/_next/static/css/64aa077ca96507d3.css" data-n-g=""/><link rel="preload" href="/_next/static/css/e491c5ad83d0116a.css" as="style"/><link rel="stylesheet" href="/_next/static/css/e491c5ad83d0116a.css" data-n-p=""/><noscript data-n-css=""></noscript><script defer="" nomodule="" src="/_next/static/chunks/polyfills-5cd94c89d3acac5f.js"></script><script src="/_next/static/chunks/webpack-514908bffb652963.js" defer=""></script><script src="/_next/static/chunks/framework-91d7f78b5b4003c8.js" defer=""></script><script src="/_next/static/chunks/main-22b044904a3f81e0.js" defer=""></script><script src="/_next/static/chunks/pages/_app-929aade252cc0f2b.js" defer=""></script><script src="/_next/static/chunks/929-712c4c3eb0b6b9a9.js" defer=""></script><script src="/_next/static/chunks/pages/%5Byear%5D/%5Bmonth%5D/%5Bday%5D/%5Bslug%5D-3cef77e4e2f15fd3.js" defer=""></script><script src="/_next/static/A_nUi3Fec0Q4xlN4r8ZIE/_buildManifest.js" defer=""></script><script src="/_next/static/A_nUi3Fec0Q4xlN4r8ZIE/_ssgManifest.js" defer=""></script><script src="/_next/static/A_nUi3Fec0Q4xlN4r8ZIE/_middlewareManifest.js" defer=""></script></head><body><div id="__next" data-reactroot=""><main class="layout_layout__Xf50c"><article class="hentry h-entry" lang="en-US"><header><h1 class="entry-title p-name">on logging</h1><time class="byline_published__8ePA_ dt-published" dateTime="2015-11-05T11:13:00.000Z">Thursday November 5, 2015</time><br/><span class="byline_byline__jNP6Q h-card">by: <span class="author fn p-author p-name">0xADADA</span></span></header><div class="entry-content e-content"><p>Application logs are useful for many reasons. They are the primary source of
troubleshooting information. Logs are essential to forensics during any rigorous
security analysis. Web server logs are often used for analysis in order to gain
insight into usage, audience, and trends.</p>
<h2>Logging</h2>
<p>Logs are time-ordered streams: there is no beginning or end, but rather an
ongoing, collated collection of events which we may wish to view in realtime as
they happen. Unix provides some excellent tools for handling streams. There are
two default output streams, <code>stdout</code> and <code>stderr</code>, available automatically to
all programs.</p>
<p>A program which uses <code>stdout</code> is equipped to log in a variety of ways without
adding any weight to its codebase or configuration format.</p>
<p>Treating your logs as streams is a form of future-proofing for your application.
Choosing to use <code>stdout</code> over custom-implementing a specific logging solution
allows your application to change logging mechanisms with 0-code changes. It
allows you to be the most agnostic as you haven't needed to make any decisions
or implementations other than adopting a long-standard convention.</p>
<p>If you run them in the foreground, as is typical of development mode, you see
the output right in your terminal. This is exactly what you want. If you run in
production mode, you can redirect the output to a file, to syslog, to both, or
to any other logging system that can accept an input stream.</p>
<p>Logging on any reasonably large distributed system will generally end up using
the syslog protocol to send logs from many components to a single location.
Programs that treat logs as files are now on the wrong path: if they wish to log
to syslog, each program needs to implement syslog internally - and provide yet
more logging configuration options to set the various syslog fields.</p>
<h3>Best Practices</h3>
<ol>
<li>An app shouldn't implement a custom logging solution. Simply write to
<code>stdout</code> and <code>stderr</code>.</li>
<li>Don't write to a log file, and don't expect log files to be managed. This
then requires log rotation and log file maintenance.</li>
</ol>
<p>During local development, the developer will view this stream in the foreground
of their terminal to observe app behavior. During production the runtime
environment will read <code>stdout</code> and <code>stderr</code> from the app, the streams will be
captured by the execution environment, collated together with all other streams
from the app, and routed to one or more final destinations for viewing and
long-term archival. These archival destinations are not visible to or
configurable by the app, and instead are completely managed by the execution
environment. Furthermore, the app needn't implement any logging solution.</p>
<p>The event stream for an app can be rerouted to a file (if needed), or watched in
a terminal. Most significantly, the stream can be sent to a log indexing and
analysis system such as Splunk. These systems allow for great power and
flexibility for introspecting an app's behavior over time, including:</p>
<ul>
<li>Finding specific events in the past.</li>
<li>Large-scale graphing of trends (such as requests per minute).</li>
<li>Active alerting according to user-defined heuristics</li>
</ul>
<h3>In Practice</h3>
<p>Already using Amazon AWS? Checkout CloudWatch, the additional advantages here
are that you could have a central source of truth for all monitoring needs
because such metrics as CPU, disk I/O, and network for your container instances
are already available on CloudWatch.</p>
<p>If using Docker,
<a href="https://github.com/docker/docker/releases/tag/v1.9.0">Docker 1.9 announced a logging driver for CloudWatch</a>.
Use these options to enable the <code>awslogs</code> Amazon AWS CloudWatch logging driver:</p>
<pre><code>--log-opt awslogs-region=&#x3C;aws_region>
--log-opt awslogs-group=&#x3C;log_group_name>
--log-opt awslogs-stream=&#x3C;log_stream_name>
</code></pre>
<p>Provide AWS credentials to the Docker daemon to use the <code>awslogs</code> logging
driver. You can provide these credentials with the <code>AWS_ACCESS_KEY_ID</code> ,
<code>AWS_SECRET_ACCESS_KEY</code>, and <code>AWS_SESSION_TOKEN</code> environment variables.</p>
<p>Credentials must have a policy applied that allows the <code>logs:CreateLogStream</code>
and <code>logs:PutLogEvents</code> actions, as shown in the following example.</p>
<pre><code>{
  "Version": "2012-10-17",
  "Statement": [
    {
      "Action": [
        "logs:CreateLogStream",
        "logs:PutLogEvents"
      ],
      "Effect": "Allow",
      "Resource": "*"
    }
  ]
}
</code></pre>
<p>Use containers to move logs from one container into another service using a
Docker logging driver. Docker allows configuration of container log driver:</p>
<pre><code>container_name:
    log_driver: syslog
      log_opt:
        syslog-tag: nginxproxy_nginx
        syslog-address: udp://MY_DOCKER_HOST
</code></pre>
<p>Using Splunk?
<a href="http://blogs.splunk.com/2015/08/24/collecting-docker-logs-and-stats-with-splunk/">Use containers to run a Splunk forwarder</a></p>
<pre><code>splunkforwarder:
  image: outcoldman/splunk:6.2-forwarder
  environment:
    - SPLUNK_FORWARD_SERVER=YOUR_DOCKER_HOSTNAME:9997
  volumes_from:
    - vforwarder
  ports:
    - 514:1514/udp
  restart: always
</code></pre>
</div><footer class="license_copyright__KOT7N">This is licensed under a Creative Commons <!-- -->cc-by-nc-sa<!-- --> International License</footer></article></main><div class="layout_layout__Xf50c"><footer class="footer_footer__OT4Wn layout_layout__Xf50c"><p>Â© 2003-<!-- -->2022<!-- --> 0xADADA (unless otherwise noted.)<br/><a title="0xADADA" href="/">Home</a> <span class="h-card"><a class="c-Meta u-email" rel="me" title="0xADADA" href="mailto:0xadada.pub@protonmail.com">Email</a> </span><a rel="me nofollow external noopener" title="0xADADA on Twitter" href="https://twitter.com/0xadada">Twitter</a> <a rel="me nofollow external noopener" title="0xADADA on GitHub" href="https://github.com/0xadada">GitHub</a> <a rel="me nofollow external noopener" title="0xADADA on Goodreads" href="https://www.goodreads.com/review/list/60524683-0xadada?shelf=wanted">Goodreads</a> </p></footer></div></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"post":{"slugs":{"year":"2015","month":"11","day":"05","slug":"on-logging"},"title":"on logging","metaDescription":"Thoughts and best practices on application logging","metaKeywords":"software engineering, web development, 12 factor","date":1446721980000,"author":"0xADADA","content":"\u003cp\u003eApplication logs are useful for many reasons. They are the primary source of\ntroubleshooting information. Logs are essential to forensics during any rigorous\nsecurity analysis. Web server logs are often used for analysis in order to gain\ninsight into usage, audience, and trends.\u003c/p\u003e\n\u003ch2\u003eLogging\u003c/h2\u003e\n\u003cp\u003eLogs are time-ordered streams: there is no beginning or end, but rather an\nongoing, collated collection of events which we may wish to view in realtime as\nthey happen. Unix provides some excellent tools for handling streams. There are\ntwo default output streams, \u003ccode\u003estdout\u003c/code\u003e and \u003ccode\u003estderr\u003c/code\u003e, available automatically to\nall programs.\u003c/p\u003e\n\u003cp\u003eA program which uses \u003ccode\u003estdout\u003c/code\u003e is equipped to log in a variety of ways without\nadding any weight to its codebase or configuration format.\u003c/p\u003e\n\u003cp\u003eTreating your logs as streams is a form of future-proofing for your application.\nChoosing to use \u003ccode\u003estdout\u003c/code\u003e over custom-implementing a specific logging solution\nallows your application to change logging mechanisms with 0-code changes. It\nallows you to be the most agnostic as you haven't needed to make any decisions\nor implementations other than adopting a long-standard convention.\u003c/p\u003e\n\u003cp\u003eIf you run them in the foreground, as is typical of development mode, you see\nthe output right in your terminal. This is exactly what you want. If you run in\nproduction mode, you can redirect the output to a file, to syslog, to both, or\nto any other logging system that can accept an input stream.\u003c/p\u003e\n\u003cp\u003eLogging on any reasonably large distributed system will generally end up using\nthe syslog protocol to send logs from many components to a single location.\nPrograms that treat logs as files are now on the wrong path: if they wish to log\nto syslog, each program needs to implement syslog internally - and provide yet\nmore logging configuration options to set the various syslog fields.\u003c/p\u003e\n\u003ch3\u003eBest Practices\u003c/h3\u003e\n\u003col\u003e\n\u003cli\u003eAn app shouldn't implement a custom logging solution. Simply write to\n\u003ccode\u003estdout\u003c/code\u003e and \u003ccode\u003estderr\u003c/code\u003e.\u003c/li\u003e\n\u003cli\u003eDon't write to a log file, and don't expect log files to be managed. This\nthen requires log rotation and log file maintenance.\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003eDuring local development, the developer will view this stream in the foreground\nof their terminal to observe app behavior. During production the runtime\nenvironment will read \u003ccode\u003estdout\u003c/code\u003e and \u003ccode\u003estderr\u003c/code\u003e from the app, the streams will be\ncaptured by the execution environment, collated together with all other streams\nfrom the app, and routed to one or more final destinations for viewing and\nlong-term archival. These archival destinations are not visible to or\nconfigurable by the app, and instead are completely managed by the execution\nenvironment. Furthermore, the app needn't implement any logging solution.\u003c/p\u003e\n\u003cp\u003eThe event stream for an app can be rerouted to a file (if needed), or watched in\na terminal. Most significantly, the stream can be sent to a log indexing and\nanalysis system such as Splunk. These systems allow for great power and\nflexibility for introspecting an app's behavior over time, including:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eFinding specific events in the past.\u003c/li\u003e\n\u003cli\u003eLarge-scale graphing of trends (such as requests per minute).\u003c/li\u003e\n\u003cli\u003eActive alerting according to user-defined heuristics\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3\u003eIn Practice\u003c/h3\u003e\n\u003cp\u003eAlready using Amazon AWS? Checkout CloudWatch, the additional advantages here\nare that you could have a central source of truth for all monitoring needs\nbecause such metrics as CPU, disk I/O, and network for your container instances\nare already available on CloudWatch.\u003c/p\u003e\n\u003cp\u003eIf using Docker,\n\u003ca href=\"https://github.com/docker/docker/releases/tag/v1.9.0\"\u003eDocker 1.9 announced a logging driver for CloudWatch\u003c/a\u003e.\nUse these options to enable the \u003ccode\u003eawslogs\u003c/code\u003e Amazon AWS CloudWatch logging driver:\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e--log-opt awslogs-region=\u0026#x3C;aws_region\u003e\n--log-opt awslogs-group=\u0026#x3C;log_group_name\u003e\n--log-opt awslogs-stream=\u0026#x3C;log_stream_name\u003e\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eProvide AWS credentials to the Docker daemon to use the \u003ccode\u003eawslogs\u003c/code\u003e logging\ndriver. You can provide these credentials with the \u003ccode\u003eAWS_ACCESS_KEY_ID\u003c/code\u003e ,\n\u003ccode\u003eAWS_SECRET_ACCESS_KEY\u003c/code\u003e, and \u003ccode\u003eAWS_SESSION_TOKEN\u003c/code\u003e environment variables.\u003c/p\u003e\n\u003cp\u003eCredentials must have a policy applied that allows the \u003ccode\u003elogs:CreateLogStream\u003c/code\u003e\nand \u003ccode\u003elogs:PutLogEvents\u003c/code\u003e actions, as shown in the following example.\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e{\n  \"Version\": \"2012-10-17\",\n  \"Statement\": [\n    {\n      \"Action\": [\n        \"logs:CreateLogStream\",\n        \"logs:PutLogEvents\"\n      ],\n      \"Effect\": \"Allow\",\n      \"Resource\": \"*\"\n    }\n  ]\n}\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eUse containers to move logs from one container into another service using a\nDocker logging driver. Docker allows configuration of container log driver:\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003econtainer_name:\n    log_driver: syslog\n      log_opt:\n        syslog-tag: nginxproxy_nginx\n        syslog-address: udp://MY_DOCKER_HOST\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eUsing Splunk?\n\u003ca href=\"http://blogs.splunk.com/2015/08/24/collecting-docker-logs-and-stats-with-splunk/\"\u003eUse containers to run a Splunk forwarder\u003c/a\u003e\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003esplunkforwarder:\n  image: outcoldman/splunk:6.2-forwarder\n  environment:\n    - SPLUNK_FORWARD_SERVER=YOUR_DOCKER_HOSTNAME:9997\n  volumes_from:\n    - vforwarder\n  ports:\n    - 514:1514/udp\n  restart: always\n\u003c/code\u003e\u003c/pre\u003e\n","slug":"2015-11-05-on-logging","license":"cc-by-nc-sa"}},"__N_SSG":true},"page":"/[year]/[month]/[day]/[slug]","query":{"year":"2015","month":"11","day":"05","slug":"on-logging"},"buildId":"A_nUi3Fec0Q4xlN4r8ZIE","isFallback":false,"gsp":true,"scriptLoader":[]}</script></body></html>